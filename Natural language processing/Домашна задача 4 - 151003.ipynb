{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашна задача 4\n",
    "## Обработка на природните јазици 2018/2019\n",
    "### Андреј Јанчевски 151003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T22:54:39.417116Z",
     "start_time": "2018-12-19T22:54:32.421189Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bani5\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bani5\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bani5\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "C:\\Users\\bani5\\AppData\\Roaming\\Python\\Python37\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('stopwords')\n",
    "stops = set(stopwords.words('english'))\n",
    "from nltk import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "import cython\n",
    "from gensim.models import word2vec\n",
    "import re\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T22:54:56.172011Z",
     "start_time": "2018-12-19T22:54:54.864405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n",
      "['id' 'sentiment' 'review']\n",
      "\"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\n",
    "    \"labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n",
    "print(train.shape)\n",
    "print(train.columns.values)\n",
    "print(train[\"review\"][0])\n",
    "train_labels = train[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T22:54:58.866017Z",
     "start_time": "2018-12-19T22:54:58.837966Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci\\'s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ\\'s music.Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ\\'s bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i\\'ve gave this subject....hmmm well i don\\'t know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example1 = BeautifulSoup(train[\"review\"][0])\n",
    "example1.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T22:55:02.353074Z",
     "start_time": "2018-12-19T22:55:01.054040Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with all this stuff go down at the moment with mj i ve start listen to his music , watch the odd documentary here and there , watch the wiz and watch moonwalker again . maybe i just want to get a certain insight into this guy who i think be really cool in the eighties just to maybe make up my mind whether he be guilty or innocent . moonwalker be part biography , part feature film which i remember go to see at the cinema when it be originally release . some of it have subtle message about mj s feel towards the press and also the obvious message of drug be bad m kay . visually impressive but of course this be all about michael jackson so unless you remotely like mj in anyway then you be go to hate this and find it bore . some may call mj an egotist for consent to the make of this movie but mj and most of his fan would say that he make it for the fan which if true be really nice of him . the actual feature film bite when it finally start be only on for num minutes or so exclude the smooth criminal sequence and joe pesci be convince as a psychopathic all powerful drug lord . why he want mj dead so bad be beyond me . because mj overhear his plan ? nah , joe pesci s character rant that he want people to know it be he who be supply drug etc so i dunno , maybe he just hat mj s music . lot of cool things in this like mj turn into a car and a robot and the whole speed demon sequence . also , the director must have have the patience of a saint when it come to film the kiddy bad sequence as usually directors hate work with one kid let alone a whole bunch of them perform a complex dance scene . bottom line , this movie be for people who like mj on one level or another which i think be most people . if not , then stay away . it do try and give off a wholesome message and ironically mj s bestest buddy in this movie be a girl ! michael jackson be truly one of the most talented people ever to grace this planet but be he guilty ? well , with all the attention i ve give this subject . . . . hmmm well i don t know because people can be different behind close doors , i know this for a fact . he be either an extremely nice but stupid guy or one of the most sickest liars . i hope he be not the latter .'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def review_to_words(raw_review,\n",
    "                    remove_stops=False,\n",
    "                    lemmatize=False,\n",
    "                    stem=False):\n",
    "    review = BeautifulSoup(raw_review).get_text()\n",
    "    filtered = re.sub('\\d+', 'NUM', review)\n",
    "    filtered = re.sub('\\.', ' \\. ', filtered)\n",
    "    filtered = re.sub('\\,', ' \\, ', filtered)\n",
    "    filtered = re.sub('\\?', ' \\? ', filtered)\n",
    "    filtered = re.sub('!', ' ! ', filtered)\n",
    "    filtered = re.sub('\\:', ' \\: ', filtered)\n",
    "    filtered = re.sub('\\-', ' \\- ', filtered)\n",
    "    filtered = re.sub('[^A-Za-z\\.\\,\\?!\\:\\-]', ' ', filtered)\n",
    "    filtered = filtered.lower()\n",
    "    words = [token for token in filtered.split(\" \") if token != '']\n",
    "    if remove_stops:\n",
    "        words = [word for word in words if word not in stops]\n",
    "    if lemmatize:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        words = [lemmatizer.lemmatize(word, pos='v') for word in words]\n",
    "    if stem:\n",
    "        ps = PorterStemmer()\n",
    "        words = [ps.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "\n",
    "\" \".join(review_to_words(train[\"review\"][0], lemmatize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T22:55:34.263784Z",
     "start_time": "2018-12-19T22:55:05.087749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 25000\n",
      "\n",
      "Review 2000 of 25000\n",
      "\n",
      "Review 3000 of 25000\n",
      "\n",
      "Review 4000 of 25000\n",
      "\n",
      "Review 5000 of 25000\n",
      "\n",
      "Review 6000 of 25000\n",
      "\n",
      "Review 7000 of 25000\n",
      "\n",
      "Review 8000 of 25000\n",
      "\n",
      "Review 9000 of 25000\n",
      "\n",
      "Review 10000 of 25000\n",
      "\n",
      "Review 11000 of 25000\n",
      "\n",
      "Review 12000 of 25000\n",
      "\n",
      "Review 13000 of 25000\n",
      "\n",
      "Review 14000 of 25000\n",
      "\n",
      "Review 15000 of 25000\n",
      "\n",
      "Review 16000 of 25000\n",
      "\n",
      "Review 17000 of 25000\n",
      "\n",
      "Review 18000 of 25000\n",
      "\n",
      "Review 19000 of 25000\n",
      "\n",
      "Review 20000 of 25000\n",
      "\n",
      "Review 21000 of 25000\n",
      "\n",
      "Review 22000 of 25000\n",
      "\n",
      "Review 23000 of 25000\n",
      "\n",
      "Review 24000 of 25000\n",
      "\n",
      "Review 25000 of 25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_clean_reviews(dataframe,\n",
    "                      remove_stops=False,\n",
    "                      lemmatize=False,\n",
    "                      stem=False):\n",
    "    num_reviews = dataframe[\"review\"].size\n",
    "    clean_reviews = []\n",
    "    for i in range(0, num_reviews):\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(\"Review \" + str(i + 1) + \" of \" + str(num_reviews) + \"\\n\")\n",
    "        clean_reviews.append(\" \".join(\n",
    "            review_to_words(dataframe[\"review\"][i], remove_stops, lemmatize,\n",
    "                            stem)))\n",
    "    return clean_reviews\n",
    "\n",
    "\n",
    "clean_train_reviews = get_clean_reviews(train, lemmatize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T22:55:42.152982Z",
     "start_time": "2018-12-19T22:55:38.283948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 5000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    analyzer=\"word\",\n",
    "    tokenizer=None,\n",
    "    preprocessor=None,\n",
    "    stop_words=None,\n",
    "    max_features=5000)\n",
    "\n",
    "\n",
    "def get_bow_dataset(clean_reviews, test=False):\n",
    "    if test:\n",
    "        features = vectorizer.transform(clean_reviews)\n",
    "    else:\n",
    "        features = vectorizer.fit_transform(clean_reviews)\n",
    "    return features.toarray()\n",
    "\n",
    "\n",
    "train_bow_dataset = get_bow_dataset(clean_train_reviews)\n",
    "train_bow_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T22:55:50.709459Z",
     "start_time": "2018-12-19T22:55:49.697410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272 abandon\n",
      "125 abc\n",
      "108 abilities\n",
      "454 ability\n",
      "1259 able\n",
      "17372 about\n",
      "817 above\n",
      "85 abraham\n",
      "73 abrupt\n",
      "116 absence\n",
      "83 absent\n",
      "352 absolute\n",
      "1485 absolutely\n",
      "153 absorb\n",
      "306 absurd\n",
      "76 absurdity\n",
      "299 abuse\n",
      "91 abusive\n",
      "98 abysmal\n",
      "297 academy\n",
      "704 accent\n",
      "575 accept\n",
      "130 acceptable\n",
      "71 acceptance\n",
      "93 access\n",
      "318 accident\n",
      "200 accidentally\n",
      "118 acclaim\n",
      "185 accompany\n",
      "223 accomplish\n",
      "306 accord\n",
      "262 account\n",
      "81 accuracy\n",
      "284 accurate\n",
      "163 accuse\n",
      "75 ace\n",
      "405 achieve\n",
      "124 achievement\n",
      "90 acid\n",
      "95 acknowledge\n",
      "97 acquire\n",
      "971 across\n",
      "8795 act\n",
      "3666 action\n",
      "75 active\n",
      "83 activities\n",
      "2389 actor\n",
      "4486 actors\n",
      "1219 actress\n",
      "369 actresses\n",
      "793 actual\n",
      "4237 actually\n",
      "143 ad\n",
      "302 adam\n",
      "98 adams\n",
      "235 adapt\n",
      "453 adaptation\n",
      "80 adaptations\n",
      "1752 add\n",
      "163 addict\n",
      "347 addition\n",
      "74 additional\n",
      "183 address\n",
      "113 adequate\n",
      "73 admirable\n",
      "212 admire\n",
      "738 admit\n",
      "134 admittedly\n",
      "76 adolescent\n",
      "138 adopt\n",
      "101 adorable\n",
      "109 adore\n",
      "510 adult\n",
      "376 adults\n",
      "247 advance\n",
      "171 advantage\n",
      "717 adventure\n",
      "171 advertise\n",
      "259 advice\n",
      "165 advise\n",
      "346 affair\n",
      "71 affairs\n",
      "312 affect\n",
      "73 affection\n",
      "130 afford\n",
      "126 aforementioned\n",
      "343 afraid\n",
      "212 africa\n",
      "255 african\n",
      "7637 after\n",
      "187 afternoon\n",
      "128 afterwards\n",
      "4008 again\n",
      "1476 against\n",
      "1724 age\n",
      "71 agency\n",
      "76 agenda\n",
      "361 agent\n",
      "94 agents\n",
      "1033 ago\n",
      "779 agree\n",
      "118 ah\n",
      "396 ahead\n",
      "273 aid\n",
      "287 aim\n",
      "176 ain\n",
      "841 air\n",
      "92 airplane\n",
      "93 airport\n",
      "194 aka\n",
      "100 akshay\n",
      "376 al\n",
      "351 alan\n",
      "86 alarm\n",
      "163 alas\n",
      "157 albeit\n",
      "265 albert\n",
      "84 album\n",
      "84 alcohol\n",
      "93 alcoholic\n",
      "81 alec\n",
      "103 alert\n",
      "231 alex\n",
      "121 alexander\n",
      "85 alfred\n",
      "199 alice\n",
      "79 alicia\n",
      "572 alien\n",
      "83 alienate\n",
      "152 alike\n",
      "86 alison\n",
      "463 alive\n",
      "23976 all\n",
      "407 allen\n",
      "1013 allow\n",
      "133 ally\n",
      "3139 almost\n",
      "1061 alone\n",
      "1776 along\n",
      "90 alongside\n",
      "1381 already\n",
      "185 alright\n",
      "9156 also\n",
      "156 alter\n",
      "120 alternate\n",
      "78 alternative\n",
      "2537 although\n",
      "114 altman\n",
      "112 altogether\n",
      "70 alvin\n",
      "3239 always\n",
      "101 amanda\n",
      "215 amateur\n",
      "216 amateurish\n",
      "1547 amaze\n",
      "174 amazingly\n",
      "75 amazon\n",
      "80 ambiguous\n",
      "118 ambition\n",
      "126 ambitious\n",
      "728 america\n",
      "2228 american\n",
      "365 americans\n",
      "92 amitabh\n",
      "783 among\n",
      "160 amongst\n",
      "597 amount\n",
      "632 amuse\n",
      "77 amusement\n",
      "104 amy\n",
      "21562 an\n",
      "88 analysis\n",
      "71 analyze\n",
      "82 anchor\n",
      "233 ancient\n",
      "164110 and\n",
      "223 anderson\n",
      "79 andre\n",
      "147 andrew\n",
      "151 andrews\n",
      "318 andy\n",
      "230 angel\n",
      "85 angela\n",
      "101 angeles\n",
      "161 angels\n",
      "226 anger\n",
      "399 angle\n",
      "336 angry\n",
      "71 angst\n",
      "342 animal\n",
      "410 animals\n",
      "540 animate\n",
      "826 animation\n",
      "240 anime\n",
      "288 ann\n",
      "251 anna\n",
      "254 anne\n",
      "117 annie\n",
      "107 announce\n",
      "1212 annoy\n",
      "4324 another\n",
      "626 answer\n",
      "263 anthony\n",
      "480 anti\n",
      "117 antic\n",
      "103 anticipate\n",
      "72 anticipation\n",
      "82 antonioni\n",
      "70 ants\n",
      "88 antwone\n",
      "7659 any\n",
      "310 anybody\n",
      "333 anymore\n",
      "2630 anyone\n",
      "2949 anything\n",
      "1117 anyway\n",
      "113 anyways\n",
      "304 anywhere\n",
      "623 apart\n",
      "339 apartment\n",
      "222 ape\n",
      "162 appal\n",
      "309 apparent\n",
      "917 apparently\n",
      "748 appeal\n",
      "1972 appear\n",
      "451 appearance\n",
      "139 appearances\n",
      "102 applaud\n",
      "170 apply\n",
      "737 appreciate\n",
      "88 appreciation\n",
      "549 approach\n",
      "228 appropriate\n",
      "77 appropriately\n",
      "101 april\n",
      "95 arc\n",
      "337 area\n",
      "116 areas\n",
      "886 aren\n",
      "90 arguably\n",
      "210 argue\n",
      "118 argument\n",
      "69 ariel\n",
      "76 arise\n",
      "425 arm\n",
      "454 army\n",
      "148 arnold\n",
      "3616 around\n",
      "98 arrange\n",
      "211 arrest\n",
      "87 arrival\n",
      "423 arrive\n",
      "99 arrogant\n",
      "1293 art\n",
      "373 arthur\n",
      "94 artificial\n",
      "331 artist\n",
      "339 artistic\n",
      "182 artists\n",
      "310 arts\n",
      "72 artsy\n",
      "46934 as\n",
      "158 ashamed\n",
      "89 ashley\n",
      "237 asian\n",
      "473 aside\n",
      "1500 ask\n",
      "213 asleep\n",
      "454 aspect\n",
      "398 aspects\n",
      "113 aspire\n",
      "267 ass\n",
      "85 assassin\n",
      "130 assault\n",
      "77 assemble\n",
      "97 assign\n",
      "68 assist\n",
      "148 assistant\n",
      "212 associate\n",
      "423 assume\n",
      "128 assure\n",
      "132 astaire\n",
      "110 astonish\n",
      "72 astound\n",
      "76 asylum\n",
      "23510 at\n",
      "111 atlantis\n",
      "735 atmosphere\n",
      "148 atmospheric\n",
      "197 atrocious\n",
      "161 attach\n",
      "822 attack\n",
      "1932 attempt\n",
      "75 attenborough\n",
      "208 attend\n",
      "906 attention\n",
      "237 attitude\n",
      "90 attitudes\n",
      "89 attorney\n",
      "230 attract\n",
      "143 attraction\n",
      "352 attractive\n",
      "84 attribute\n",
      "2199 audience\n",
      "476 audiences\n",
      "113 audio\n",
      "103 audition\n",
      "173 aunt\n",
      "91 austen\n",
      "82 austin\n",
      "126 australia\n",
      "206 australian\n",
      "166 authentic\n",
      "323 author\n",
      "101 authority\n",
      "75 automatically\n",
      "388 available\n",
      "69 avenge\n",
      "726 average\n",
      "975 avoid\n",
      "111 await\n",
      "126 awake\n",
      "119 awaken\n",
      "712 award\n",
      "277 aware\n",
      "2775 away\n",
      "116 awe\n",
      "485 awesome\n",
      "1724 awful\n",
      "84 awfully\n",
      "78 awhile\n",
      "248 awkward\n",
      "100 babe\n",
      "770 baby\n",
      "90 bacall\n",
      "69 bachelor\n",
      "5133 back\n",
      "105 backdrop\n",
      "719 background\n",
      "77 bacon\n",
      "9301 bad\n",
      "662 badly\n",
      "73 baffle\n",
      "186 bag\n",
      "81 bake\n",
      "155 baker\n",
      "130 bakshi\n",
      "256 balance\n",
      "80 baldwin\n",
      "388 ball\n",
      "94 ballet\n",
      "140 ban\n",
      "71 banal\n",
      "627 band\n",
      "153 bang\n",
      "318 bank\n",
      "68 banter\n",
      "502 bar\n",
      "243 barbara\n",
      "114 bare\n",
      "483 barely\n",
      "110 bargain\n",
      "87 barrel\n",
      "134 barry\n",
      "88 barrymore\n",
      "1642 base\n",
      "215 baseball\n",
      "143 basement\n",
      "121 bash\n",
      "519 basic\n",
      "906 basically\n",
      "77 basinger\n",
      "169 basis\n",
      "88 basketball\n",
      "290 bat\n",
      "154 bath\n",
      "114 bathroom\n",
      "432 batman\n",
      "795 battle\n",
      "93 bay\n",
      "174 bbc\n",
      "241508 be\n",
      "216 beach\n",
      "71 bean\n",
      "845 bear\n",
      "70 beard\n",
      "187 beast\n",
      "743 beat\n",
      "74 beatles\n",
      "113 beatty\n",
      "2177 beautiful\n",
      "436 beautifully\n",
      "655 beauty\n",
      "9045 because\n",
      "3969 become\n",
      "415 bed\n",
      "107 bedroom\n",
      "123 beer\n",
      "4320 before\n",
      "111 befriend\n",
      "182 beg\n",
      "3249 begin\n",
      "191 behave\n",
      "261 behavior\n",
      "75 behaviour\n",
      "1280 behind\n",
      "76 behold\n",
      "94 bela\n",
      "188 belief\n",
      "92 beliefs\n",
      "711 believable\n",
      "3078 believe\n",
      "141 bell\n",
      "286 belong\n",
      "178 beloved\n",
      "274 below\n",
      "95 belt\n",
      "87 belushi\n",
      "616 ben\n",
      "163 bend\n",
      "104 beneath\n",
      "175 benefit\n",
      "96 bergman\n",
      "99 berlin\n",
      "75 bernard\n",
      "71 beside\n",
      "410 besides\n",
      "6424 best\n",
      "287 bet\n",
      "107 betray\n",
      "73 betrayal\n",
      "155 bette\n",
      "5746 better\n",
      "163 bettie\n",
      "89 betty\n",
      "3390 between\n",
      "76 beverly\n",
      "73 beware\n",
      "866 beyond\n",
      "127 bias\n",
      "134 bible\n",
      "3477 big\n",
      "268 bigger\n",
      "515 biggest\n",
      "89 bike\n",
      "89 biko\n",
      "792 bill\n",
      "375 billy\n",
      "118 bin\n",
      "205 bind\n",
      "82 biography\n",
      "229 bird\n",
      "204 birth\n",
      "137 birthday\n",
      "100 bitch\n",
      "3336 bite\n",
      "295 bits\n",
      "164 bitter\n",
      "499 bizarre\n",
      "2117 black\n",
      "71 blackmail\n",
      "95 blade\n",
      "195 blah\n",
      "167 blair\n",
      "110 blake\n",
      "394 blame\n",
      "273 bland\n",
      "153 blank\n",
      "130 blast\n",
      "104 blatant\n",
      "119 bleak\n",
      "107 bleed\n",
      "200 blend\n",
      "120 bless\n",
      "308 blind\n",
      "124 blob\n",
      "166 block\n",
      "187 blockbuster\n",
      "97 blond\n",
      "270 blonde\n",
      "1245 blood\n",
      "313 bloody\n",
      "79 bloom\n",
      "721 blow\n",
      "531 blue\n",
      "96 blunt\n",
      "156 bo\n",
      "330 board\n",
      "113 boast\n",
      "283 boat\n",
      "279 bob\n",
      "138 bobby\n",
      "1199 body\n",
      "124 boil\n",
      "102 bold\n",
      "143 boll\n",
      "169 bollywood\n",
      "385 bomb\n",
      "417 bond\n",
      "183 bone\n",
      "97 bonus\n",
      "69 boob\n",
      "2933 book\n",
      "102 boom\n",
      "149 boot\n",
      "205 border\n",
      "2549 bore\n",
      "141 boredom\n",
      "188 borrow\n",
      "468 boss\n",
      "71 boston\n",
      "3406 both\n",
      "655 bother\n",
      "113 bottle\n",
      "435 bottom\n",
      "73 bounce\n",
      "190 bourne\n",
      "96 bow\n",
      "105 bowl\n",
      "813 box\n",
      "75 boxer\n",
      "1560 boy\n",
      "399 boyfriend\n",
      "79 boyle\n",
      "618 boys\n",
      "176 brad\n",
      "109 brady\n",
      "601 brain\n",
      "186 branagh\n",
      "148 brand\n",
      "158 brando\n",
      "209 brave\n",
      "116 brazil\n",
      "76 bread\n",
      "1530 break\n",
      "192 breast\n",
      "177 breath\n",
      "121 breathe\n",
      "168 breathtaking\n",
      "117 breed\n",
      "84 brenda\n",
      "73 brendan\n",
      "352 brian\n",
      "136 bride\n",
      "227 bridge\n",
      "78 bridget\n",
      "402 brief\n",
      "135 briefly\n",
      "273 bright\n",
      "129 brilliance\n",
      "1195 brilliant\n",
      "248 brilliantly\n",
      "2452 bring\n",
      "149 britain\n",
      "898 british\n",
      "115 broad\n",
      "151 broadcast\n",
      "242 broadway\n",
      "73 bronson\n",
      "74 brood\n",
      "185 brook\n",
      "105 brooklyn\n",
      "71 bros\n",
      "128 brosnan\n",
      "1107 brother\n",
      "557 brothers\n",
      "292 brown\n",
      "393 bruce\n",
      "69 brush\n",
      "303 brutal\n",
      "81 brutality\n",
      "90 brutally\n",
      "89 bubble\n",
      "303 buck\n",
      "134 bud\n",
      "109 buddies\n",
      "258 buddy\n",
      "1928 budget\n",
      "203 buff\n",
      "89 buffalo\n",
      "285 bug\n",
      "1157 build\n",
      "113 bull\n",
      "109 bullet\n",
      "124 bullets\n",
      "161 bully\n",
      "97 bumble\n",
      "89 bump\n",
      "819 bunch\n",
      "78 bunny\n",
      "619 burn\n",
      "132 burst\n",
      "167 burt\n",
      "152 burton\n",
      "190 bury\n",
      "204 bus\n",
      "150 bush\n",
      "624 business\n",
      "83 businessman\n",
      "111 bust\n",
      "81 buster\n",
      "163 busy\n",
      "42615 but\n",
      "127 butcher\n",
      "86 butler\n",
      "153 butt\n",
      "138 button\n",
      "1465 buy\n",
      "74 buzz\n",
      "22542 by\n",
      "74 bye\n",
      "180 cabin\n",
      "285 cable\n",
      "334 cage\n",
      "124 cagney\n",
      "204 caine\n",
      "107 cake\n",
      "84 caliber\n",
      "189 california\n",
      "2792 call\n",
      "92 calm\n",
      "67 camcorder\n",
      "259 cameo\n",
      "146 cameos\n",
      "1778 camera\n",
      "110 cameras\n",
      "123 cameron\n",
      "546 camp\n",
      "84 campaign\n",
      "97 campbell\n",
      "179 campy\n",
      "14721 can\n",
      "139 canada\n",
      "226 canadian\n",
      "142 cancel\n",
      "75 cancer\n",
      "72 candle\n",
      "292 candy\n",
      "84 cannibal\n",
      "91 cannon\n",
      "1096 cannot\n",
      "207 cant\n",
      "74 canyon\n",
      "84 cap\n",
      "228 capable\n",
      "89 capital\n",
      "341 captain\n",
      "185 captivate\n",
      "852 capture\n",
      "1225 car\n",
      "249 card\n",
      "131 cardboard\n",
      "1900 care\n",
      "1116 career\n",
      "90 careful\n",
      "134 carefully\n",
      "88 carell\n",
      "68 carey\n",
      "147 caricature\n",
      "109 carl\n",
      "85 carla\n",
      "141 carol\n",
      "167 carpenter\n",
      "94 carradine\n",
      "131 carrey\n",
      "117 carrie\n",
      "820 carry\n",
      "279 cars\n",
      "151 carter\n",
      "753 cartoon\n",
      "108 cary\n",
      "1706 case\n",
      "258 cash\n",
      "70 cassavetes\n",
      "85 cassidy\n",
      "4560 cast\n",
      "357 castle\n",
      "69 casual\n",
      "661 cat\n",
      "1202 catch\n",
      "91 catchy\n",
      "211 category\n",
      "142 catherine\n",
      "152 catholic\n",
      "75 cattle\n",
      "1044 cause\n",
      "128 cave\n",
      "97 cd\n",
      "150 celebrate\n",
      "76 celebration\n",
      "102 celebrity\n",
      "176 cell\n",
      "107 celluloid\n",
      "83 censor\n",
      "445 center\n",
      "411 central\n",
      "110 centre\n",
      "528 century\n",
      "764 certain\n",
      "1462 certainly\n",
      "96 cg\n",
      "325 cgi\n",
      "180 chain\n",
      "73 chainsaw\n",
      "181 chair\n",
      "403 challenge\n",
      "95 champion\n",
      "81 championship\n",
      "207 chan\n",
      "1204 chance\n",
      "2024 change\n",
      "547 channel\n",
      "105 chaos\n",
      "150 chaplin\n",
      "88 chapter\n",
      "14177 character\n",
      "123 characterization\n",
      "308 charge\n",
      "138 charisma\n",
      "135 charismatic\n",
      "408 charles\n",
      "439 charlie\n",
      "98 charlotte\n",
      "965 charm\n",
      "824 chase\n",
      "76 chavez\n",
      "217 che\n",
      "892 cheap\n",
      "258 cheat\n",
      "1011 check\n",
      "126 cheek\n",
      "178 cheer\n",
      "164 cheese\n",
      "634 cheesy\n",
      "490 chemistry\n",
      "68 cher\n",
      "96 chess\n",
      "93 chest\n",
      "126 chew\n",
      "92 chicago\n",
      "233 chick\n",
      "80 chicken\n",
      "89 chicks\n",
      "229 chief\n",
      "1320 child\n",
      "356 childhood\n",
      "117 childish\n",
      "1510 children\n",
      "303 chill\n",
      "188 china\n",
      "337 chinese\n",
      "528 choice\n",
      "171 choices\n",
      "67 choke\n",
      "812 choose\n",
      "163 chop\n",
      "76 choppy\n",
      "107 choreograph\n",
      "115 choreography\n",
      "99 chorus\n",
      "421 chris\n",
      "183 christ\n",
      "373 christian\n",
      "79 christianity\n",
      "92 christians\n",
      "73 christine\n",
      "623 christmas\n",
      "415 christopher\n",
      "97 christy\n",
      "88 chronicle\n",
      "155 chuck\n",
      "150 chuckle\n",
      "428 church\n",
      "123 cia\n",
      "233 cinderella\n",
      "1491 cinema\n",
      "412 cinematic\n",
      "101 cinematographer\n",
      "983 cinematography\n",
      "166 circle\n",
      "218 circumstances\n",
      "72 circus\n",
      "88 cities\n",
      "125 citizen\n",
      "75 citizens\n",
      "1195 city\n",
      "140 civil\n",
      "93 civilization\n",
      "595 claim\n",
      "173 claire\n",
      "69 clan\n",
      "204 clark\n",
      "76 clarke\n",
      "82 clash\n",
      "1012 class\n",
      "1828 classic\n",
      "88 classical\n",
      "233 classics\n",
      "80 claus\n",
      "68 claustrophobic\n",
      "342 clean\n",
      "818 clear\n",
      "899 clearly\n",
      "81 clerk\n",
      "533 clever\n",
      "94 cleverly\n",
      "840 clich\n",
      "96 cliche\n",
      "82 click\n",
      "112 cliff\n",
      "93 climactic\n",
      "448 climax\n",
      "150 climb\n",
      "110 clint\n",
      "259 clip\n",
      "128 clock\n",
      "93 clone\n",
      "1592 close\n",
      "140 closely\n",
      "206 closer\n",
      "94 closest\n",
      "128 closet\n",
      "526 clothe\n",
      "83 cloud\n",
      "127 clown\n",
      "466 club\n",
      "350 clue\n",
      "68 clueless\n",
      "105 clumsy\n",
      "602 co\n",
      "129 coach\n",
      "90 coast\n",
      "73 coaster\n",
      "107 coat\n",
      "241 code\n",
      "106 coffee\n",
      "69 cohen\n",
      "109 coherent\n",
      "76 coincidence\n",
      "571 cold\n",
      "132 cole\n",
      "68 colin\n",
      "108 collapse\n",
      "127 collect\n",
      "343 collection\n",
      "496 college\n",
      "106 colonel\n",
      "665 color\n",
      "144 colorful\n",
      "216 colour\n",
      "206 columbo\n",
      "218 com\n",
      "114 combat\n",
      "231 combination\n",
      "390 combine\n",
      "8411 come\n",
      "159 comedian\n",
      "77 comedians\n",
      "315 comedic\n",
      "439 comedies\n",
      "3244 comedy\n",
      "129 comfort\n",
      "110 comfortable\n",
      "901 comic\n",
      "171 comical\n",
      "133 comics\n",
      "180 command\n",
      "70 commander\n",
      "1597 comment\n",
      "318 commentary\n",
      "239 commercial\n",
      "116 commercials\n",
      "420 commit\n",
      "509 common\n",
      "113 communicate\n",
      "103 communist\n",
      "290 community\n",
      "137 companion\n",
      "596 company\n",
      "989 compare\n",
      "251 comparison\n",
      "69 comparisons\n",
      "81 compassion\n",
      "491 compel\n",
      "81 compensate\n",
      "102 compete\n",
      "140 competent\n",
      "127 competition\n",
      "265 complain\n",
      "139 complaint\n",
      "77 complaints\n",
      "1133 complete\n",
      "1889 completely\n",
      "427 complex\n",
      "90 compl"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 10000 exceeded with 12741 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "dist = np.sum(train_bow_dataset, axis=0)\n",
    "\n",
    "for tag, count in zip(vocab, dist):\n",
    "    print(count, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T00:54:35.699613Z",
     "start_time": "2018-12-20T00:54:35.656614Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "naive_bayes = GaussianNB()\n",
    "knn = KNeighborsClassifier(\n",
    "    n_neighbors=20,\n",
    "    weights=\"distance\",\n",
    "    algorithm=\"auto\",\n",
    "    metric=\"cosine\",\n",
    "    n_jobs=-1)\n",
    "svm = SVC(\n",
    "    C=1e8,\n",
    "    kernel='rbf',\n",
    "    gamma=\"scale\",\n",
    "    decision_function_shape=\"ovr\",\n",
    "    class_weight=\"balanced\")\n",
    "logistic_regression = LogisticRegression(\n",
    "    C=1e8,\n",
    "    solver='newton-cg',\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1)\n",
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=1000,\n",
    "    criterion=\"entropy\",\n",
    "    min_samples_leaf=5,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1)\n",
    "neural_network = MLPClassifier(\n",
    "    hidden_layer_sizes=(200, 100),\n",
    "    activation=\"tanh\",\n",
    "    solver=\"adam\",\n",
    "    learning_rate=\"adaptive\",\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=1000,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T00:54:40.662614Z",
     "start_time": "2018-12-20T00:54:40.653613Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def train_and_score_classifiers(train_dataset, train_labels):\n",
    "    rows, cols = train_dataset.shape\n",
    "    validation_dataset = train_dataset[int(0.8 * rows):]\n",
    "    validation_labels = train_labels[int(0.8 * rows):]\n",
    "    train_dataset = train_dataset[:int(0.8 * rows)]\n",
    "    train_labels = train_labels[:int(0.8 * rows)]\n",
    "\n",
    "    print(train_dataset.shape)\n",
    "    print(validation_dataset.shape)\n",
    "\n",
    "    scores = {}\n",
    "\n",
    "    naive_bayes.fit(train_dataset, train_labels)\n",
    "    predicted_labels = naive_bayes.predict(validation_dataset)\n",
    "    scores[naive_bayes] = roc_auc_score(validation_labels, predicted_labels)\n",
    "    print(\"Naive Bayes done\")\n",
    "\n",
    "    knn.fit(train_dataset, train_labels)\n",
    "    predicted_labels = knn.predict(validation_dataset)\n",
    "    scores[knn] = roc_auc_score(validation_labels, predicted_labels)\n",
    "    print(\"KNN done\")\n",
    "\n",
    "    #logistic_regression.fit(train_dataset, train_labels)\n",
    "    #predicted_labels = logistic_regression.predict(validation_dataset)\n",
    "    #scores[logistic_regression] = roc_auc_score(validation_labels,\n",
    "    #                                            predicted_labels)\n",
    "    #print(\"Logistic Regression done\")\n",
    "\n",
    "    #svm.fit(train_dataset, train_labels)\n",
    "    #predicted_labels = svm.predict(validation_dataset)\n",
    "    #scores[svm] = roc_auc_score(validation_labels, predicted_labels)\n",
    "    #print(\"SVM done\")\n",
    "\n",
    "    neural_network.fit(train_dataset, train_labels)\n",
    "    predicted_labels = neural_network.predict(validation_dataset)\n",
    "    scores[neural_network] = roc_auc_score(validation_labels, predicted_labels)\n",
    "    print(\"Neural Network done\")\n",
    "\n",
    "    random_forest.fit(train_dataset, train_labels)\n",
    "    predicted_labels = random_forest.predict(validation_dataset)\n",
    "    scores[random_forest] = roc_auc_score(validation_labels, predicted_labels)\n",
    "    print(\"Random Forest done\")\n",
    "\n",
    "    print(scores.values())\n",
    "\n",
    "    best_model = max(scores.items(), key=lambda x: x[1])\n",
    "    best_model = best_model[0]\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T01:25:16.689889Z",
     "start_time": "2018-12-20T01:22:00.413993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 5000)\n",
      "(5000, 5000)\n",
      "Naive Bayes done\n",
      "KNN done\n",
      "Neural Network done\n",
      "Random Forest done\n",
      "dict_values([0.7285451487034533, 0.6709788875916595, 0.8691195823604112, 0.8532225482364508])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(200, 100), learning_rate='adaptive',\n",
       "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = train_and_score_classifiers(train_bow_dataset, train_labels)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T22:59:17.892165Z",
     "start_time": "2018-12-19T22:58:44.973898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "Review 1000 of 25000\n",
      "\n",
      "Review 2000 of 25000\n",
      "\n",
      "Review 3000 of 25000\n",
      "\n",
      "Review 4000 of 25000\n",
      "\n",
      "Review 5000 of 25000\n",
      "\n",
      "Review 6000 of 25000\n",
      "\n",
      "Review 7000 of 25000\n",
      "\n",
      "Review 8000 of 25000\n",
      "\n",
      "Review 9000 of 25000\n",
      "\n",
      "Review 10000 of 25000\n",
      "\n",
      "Review 11000 of 25000\n",
      "\n",
      "Review 12000 of 25000\n",
      "\n",
      "Review 13000 of 25000\n",
      "\n",
      "Review 14000 of 25000\n",
      "\n",
      "Review 15000 of 25000\n",
      "\n",
      "Review 16000 of 25000\n",
      "\n",
      "Review 17000 of 25000\n",
      "\n",
      "Review 18000 of 25000\n",
      "\n",
      "Review 19000 of 25000\n",
      "\n",
      "Review 20000 of 25000\n",
      "\n",
      "Review 21000 of 25000\n",
      "\n",
      "Review 22000 of 25000\n",
      "\n",
      "Review 23000 of 25000\n",
      "\n",
      "Review 24000 of 25000\n",
      "\n",
      "Review 25000 of 25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"testData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n",
    "print(test.shape)\n",
    "clean_test_reviews = get_clean_reviews(test, lemmatize=True)\n",
    "test_bow_dataset = get_bow_dataset(clean_test_reviews, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T00:16:11.045099Z",
     "start_time": "2018-12-20T00:16:11.041099Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_submission(submission_name, model, test_dataframe, test_dataset):\n",
    "    result = model.predict(test_dataset)\n",
    "    output = pd.DataFrame(data={\n",
    "        \"id\": test_dataframe[\"id\"],\n",
    "        \"sentiment\": result\n",
    "    })\n",
    "    output.to_csv(submission_name, index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T22:59:19.815161Z",
     "start_time": "2018-12-19T22:59:19.015128Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_submission(\"Andrej_Janchevski.csv\", best_model, test,\n",
    "                    test_bow_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T22:59:21.909217Z",
     "start_time": "2018-12-19T22:59:20.354168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_train = pd.read_csv(\n",
    "    \"unlabeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n",
    "unlabeled_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T23:00:20.508218Z",
     "start_time": "2018-12-19T22:59:22.469217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 50000\n",
      "\n",
      "Review 2000 of 50000\n",
      "\n",
      "Review 3000 of 50000\n",
      "\n",
      "Review 4000 of 50000\n",
      "\n",
      "Review 5000 of 50000\n",
      "\n",
      "Review 6000 of 50000\n",
      "\n",
      "Review 7000 of 50000\n",
      "\n",
      "Review 8000 of 50000\n",
      "\n",
      "Review 9000 of 50000\n",
      "\n",
      "Review 10000 of 50000\n",
      "\n",
      "Review 11000 of 50000\n",
      "\n",
      "Review 12000 of 50000\n",
      "\n",
      "Review 13000 of 50000\n",
      "\n",
      "Review 14000 of 50000\n",
      "\n",
      "Review 15000 of 50000\n",
      "\n",
      "Review 16000 of 50000\n",
      "\n",
      "Review 17000 of 50000\n",
      "\n",
      "Review 18000 of 50000\n",
      "\n",
      "Review 19000 of 50000\n",
      "\n",
      "Review 20000 of 50000\n",
      "\n",
      "Review 21000 of 50000\n",
      "\n",
      "Review 22000 of 50000\n",
      "\n",
      "Review 23000 of 50000\n",
      "\n",
      "Review 24000 of 50000\n",
      "\n",
      "Review 25000 of 50000\n",
      "\n",
      "Review 26000 of 50000\n",
      "\n",
      "Review 27000 of 50000\n",
      "\n",
      "Review 28000 of 50000\n",
      "\n",
      "Review 29000 of 50000\n",
      "\n",
      "Review 30000 of 50000\n",
      "\n",
      "Review 31000 of 50000\n",
      "\n",
      "Review 32000 of 50000\n",
      "\n",
      "Review 33000 of 50000\n",
      "\n",
      "Review 34000 of 50000\n",
      "\n",
      "Review 35000 of 50000\n",
      "\n",
      "Review 36000 of 50000\n",
      "\n",
      "Review 37000 of 50000\n",
      "\n",
      "Review 38000 of 50000\n",
      "\n",
      "Review 39000 of 50000\n",
      "\n",
      "Review 40000 of 50000\n",
      "\n",
      "Review 41000 of 50000\n",
      "\n",
      "Review 42000 of 50000\n",
      "\n",
      "Review 43000 of 50000\n",
      "\n",
      "Review 44000 of 50000\n",
      "\n",
      "Review 45000 of 50000\n",
      "\n",
      "Review 46000 of 50000\n",
      "\n",
      "Review 47000 of 50000\n",
      "\n",
      "Review 48000 of 50000\n",
      "\n",
      "Review 49000 of 50000\n",
      "\n",
      "Review 50000 of 50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_unlabeled_train_reviews = get_clean_reviews(\n",
    "    unlabeled_train, lemmatize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T23:00:28.465221Z",
     "start_time": "2018-12-19T23:00:28.430206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['with',\n",
       "  'all',\n",
       "  'this',\n",
       "  'stuff',\n",
       "  'go',\n",
       "  'down',\n",
       "  'at',\n",
       "  'the',\n",
       "  'moment',\n",
       "  'with',\n",
       "  'mj',\n",
       "  'i',\n",
       "  've',\n",
       "  'start',\n",
       "  'listen',\n",
       "  'to',\n",
       "  'his',\n",
       "  'music',\n",
       "  ',',\n",
       "  'watch',\n",
       "  'the',\n",
       "  'odd',\n",
       "  'documentary',\n",
       "  'here',\n",
       "  'and',\n",
       "  'there',\n",
       "  ',',\n",
       "  'watch',\n",
       "  'the',\n",
       "  'wiz',\n",
       "  'and',\n",
       "  'watch',\n",
       "  'moonwalker',\n",
       "  'again',\n",
       "  '.'],\n",
       " ['maybe',\n",
       "  'i',\n",
       "  'just',\n",
       "  'want',\n",
       "  'to',\n",
       "  'get',\n",
       "  'a',\n",
       "  'certain',\n",
       "  'insight',\n",
       "  'into',\n",
       "  'this',\n",
       "  'guy',\n",
       "  'who',\n",
       "  'i',\n",
       "  'think',\n",
       "  'be',\n",
       "  'really',\n",
       "  'cool',\n",
       "  'in',\n",
       "  'the',\n",
       "  'eighties',\n",
       "  'just',\n",
       "  'to',\n",
       "  'maybe',\n",
       "  'make',\n",
       "  'up',\n",
       "  'my',\n",
       "  'mind',\n",
       "  'whether',\n",
       "  'he',\n",
       "  'be',\n",
       "  'guilty',\n",
       "  'or',\n",
       "  'innocent',\n",
       "  '.'],\n",
       " ['moonwalker',\n",
       "  'be',\n",
       "  'part',\n",
       "  'biography',\n",
       "  ',',\n",
       "  'part',\n",
       "  'feature',\n",
       "  'film',\n",
       "  'which',\n",
       "  'i',\n",
       "  'remember',\n",
       "  'go',\n",
       "  'to',\n",
       "  'see',\n",
       "  'at',\n",
       "  'the',\n",
       "  'cinema',\n",
       "  'when',\n",
       "  'it',\n",
       "  'be',\n",
       "  'originally',\n",
       "  'release',\n",
       "  '.'],\n",
       " ['some',\n",
       "  'of',\n",
       "  'it',\n",
       "  'have',\n",
       "  'subtle',\n",
       "  'message',\n",
       "  'about',\n",
       "  'mj',\n",
       "  's',\n",
       "  'feel',\n",
       "  'towards',\n",
       "  'the',\n",
       "  'press',\n",
       "  'and',\n",
       "  'also',\n",
       "  'the',\n",
       "  'obvious',\n",
       "  'message',\n",
       "  'of',\n",
       "  'drug',\n",
       "  'be',\n",
       "  'bad',\n",
       "  'm',\n",
       "  'kay',\n",
       "  '.',\n",
       "  'visually',\n",
       "  'impressive',\n",
       "  'but',\n",
       "  'of',\n",
       "  'course',\n",
       "  'this',\n",
       "  'be',\n",
       "  'all',\n",
       "  'about',\n",
       "  'michael',\n",
       "  'jackson',\n",
       "  'so',\n",
       "  'unless',\n",
       "  'you',\n",
       "  'remotely',\n",
       "  'like',\n",
       "  'mj',\n",
       "  'in',\n",
       "  'anyway',\n",
       "  'then',\n",
       "  'you',\n",
       "  'be',\n",
       "  'go',\n",
       "  'to',\n",
       "  'hate',\n",
       "  'this',\n",
       "  'and',\n",
       "  'find',\n",
       "  'it',\n",
       "  'bore',\n",
       "  '.'],\n",
       " ['some',\n",
       "  'may',\n",
       "  'call',\n",
       "  'mj',\n",
       "  'an',\n",
       "  'egotist',\n",
       "  'for',\n",
       "  'consent',\n",
       "  'to',\n",
       "  'the',\n",
       "  'make',\n",
       "  'of',\n",
       "  'this',\n",
       "  'movie',\n",
       "  'but',\n",
       "  'mj',\n",
       "  'and',\n",
       "  'most',\n",
       "  'of',\n",
       "  'his',\n",
       "  'fan',\n",
       "  'would',\n",
       "  'say',\n",
       "  'that',\n",
       "  'he',\n",
       "  'make',\n",
       "  'it',\n",
       "  'for',\n",
       "  'the',\n",
       "  'fan',\n",
       "  'which',\n",
       "  'if',\n",
       "  'true',\n",
       "  'be',\n",
       "  'really',\n",
       "  'nice',\n",
       "  'of',\n",
       "  'him',\n",
       "  '.',\n",
       "  'the',\n",
       "  'actual',\n",
       "  'feature',\n",
       "  'film',\n",
       "  'bite',\n",
       "  'when',\n",
       "  'it',\n",
       "  'finally',\n",
       "  'start',\n",
       "  'be',\n",
       "  'only',\n",
       "  'on',\n",
       "  'for',\n",
       "  'num',\n",
       "  'minutes',\n",
       "  'or',\n",
       "  'so',\n",
       "  'exclude',\n",
       "  'the',\n",
       "  'smooth',\n",
       "  'criminal',\n",
       "  'sequence',\n",
       "  'and',\n",
       "  'joe',\n",
       "  'pesci',\n",
       "  'be',\n",
       "  'convince',\n",
       "  'as',\n",
       "  'a',\n",
       "  'psychopathic',\n",
       "  'all',\n",
       "  'powerful',\n",
       "  'drug',\n",
       "  'lord',\n",
       "  '.'],\n",
       " ['why', 'he', 'want', 'mj', 'dead', 'so', 'bad', 'be', 'beyond', 'me', '.'],\n",
       " ['because', 'mj', 'overhear', 'his', 'plan', '?'],\n",
       " ['nah',\n",
       "  ',',\n",
       "  'joe',\n",
       "  'pesci',\n",
       "  's',\n",
       "  'character',\n",
       "  'rant',\n",
       "  'that',\n",
       "  'he',\n",
       "  'want',\n",
       "  'people',\n",
       "  'to',\n",
       "  'know',\n",
       "  'it',\n",
       "  'be',\n",
       "  'he',\n",
       "  'who',\n",
       "  'be',\n",
       "  'supply',\n",
       "  'drug',\n",
       "  'etc',\n",
       "  'so',\n",
       "  'i',\n",
       "  'dunno',\n",
       "  ',',\n",
       "  'maybe',\n",
       "  'he',\n",
       "  'just',\n",
       "  'hat',\n",
       "  'mj',\n",
       "  's',\n",
       "  'music',\n",
       "  '.',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'cool',\n",
       "  'things',\n",
       "  'in',\n",
       "  'this',\n",
       "  'like',\n",
       "  'mj',\n",
       "  'turn',\n",
       "  'into',\n",
       "  'a',\n",
       "  'car',\n",
       "  'and',\n",
       "  'a',\n",
       "  'robot',\n",
       "  'and',\n",
       "  'the',\n",
       "  'whole',\n",
       "  'speed',\n",
       "  'demon',\n",
       "  'sequence',\n",
       "  '.'],\n",
       " ['also',\n",
       "  ',',\n",
       "  'the',\n",
       "  'director',\n",
       "  'must',\n",
       "  'have',\n",
       "  'have',\n",
       "  'the',\n",
       "  'patience',\n",
       "  'of',\n",
       "  'a',\n",
       "  'saint',\n",
       "  'when',\n",
       "  'it',\n",
       "  'come',\n",
       "  'to',\n",
       "  'film',\n",
       "  'the',\n",
       "  'kiddy',\n",
       "  'bad',\n",
       "  'sequence',\n",
       "  'as',\n",
       "  'usually',\n",
       "  'directors',\n",
       "  'hate',\n",
       "  'work',\n",
       "  'with',\n",
       "  'one',\n",
       "  'kid',\n",
       "  'let',\n",
       "  'alone',\n",
       "  'a',\n",
       "  'whole',\n",
       "  'bunch',\n",
       "  'of',\n",
       "  'them',\n",
       "  'perform',\n",
       "  'a',\n",
       "  'complex',\n",
       "  'dance',\n",
       "  'scene',\n",
       "  '.',\n",
       "  'bottom',\n",
       "  'line',\n",
       "  ',',\n",
       "  'this',\n",
       "  'movie',\n",
       "  'be',\n",
       "  'for',\n",
       "  'people',\n",
       "  'who',\n",
       "  'like',\n",
       "  'mj',\n",
       "  'on',\n",
       "  'one',\n",
       "  'level',\n",
       "  'or',\n",
       "  'another',\n",
       "  'which',\n",
       "  'i',\n",
       "  'think',\n",
       "  'be',\n",
       "  'most',\n",
       "  'people',\n",
       "  '.'],\n",
       " ['if', 'not', ',', 'then', 'stay', 'away', '.'],\n",
       " ['it',\n",
       "  'do',\n",
       "  'try',\n",
       "  'and',\n",
       "  'give',\n",
       "  'off',\n",
       "  'a',\n",
       "  'wholesome',\n",
       "  'message',\n",
       "  'and',\n",
       "  'ironically',\n",
       "  'mj',\n",
       "  's',\n",
       "  'bestest',\n",
       "  'buddy',\n",
       "  'in',\n",
       "  'this',\n",
       "  'movie',\n",
       "  'be',\n",
       "  'a',\n",
       "  'girl',\n",
       "  '!'],\n",
       " ['michael',\n",
       "  'jackson',\n",
       "  'be',\n",
       "  'truly',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'most',\n",
       "  'talented',\n",
       "  'people',\n",
       "  'ever',\n",
       "  'to',\n",
       "  'grace',\n",
       "  'this',\n",
       "  'planet',\n",
       "  'but',\n",
       "  'be',\n",
       "  'he',\n",
       "  'guilty',\n",
       "  '?'],\n",
       " ['well',\n",
       "  ',',\n",
       "  'with',\n",
       "  'all',\n",
       "  'the',\n",
       "  'attention',\n",
       "  'i',\n",
       "  've',\n",
       "  'give',\n",
       "  'this',\n",
       "  'subject',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  'hmmm',\n",
       "  'well',\n",
       "  'i',\n",
       "  'don',\n",
       "  't',\n",
       "  'know',\n",
       "  'because',\n",
       "  'people',\n",
       "  'can',\n",
       "  'be',\n",
       "  'different',\n",
       "  'behind',\n",
       "  'close',\n",
       "  'doors',\n",
       "  ',',\n",
       "  'i',\n",
       "  'know',\n",
       "  'this',\n",
       "  'for',\n",
       "  'a',\n",
       "  'fact',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'be',\n",
       "  'either',\n",
       "  'an',\n",
       "  'extremely',\n",
       "  'nice',\n",
       "  'but',\n",
       "  'stupid',\n",
       "  'guy',\n",
       "  'or',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'most',\n",
       "  'sickest',\n",
       "  'liars',\n",
       "  '.'],\n",
       " ['i', 'hope', 'he', 'be', 'not', 'the', 'latter', '.']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "\n",
    "def review_to_sentences(review,\n",
    "                        remove_stops=False,\n",
    "                        lemmatize=False,\n",
    "                        stem=False):\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(\n",
    "                review_to_words(raw_sentence, remove_stops, lemmatize, stem))\n",
    "    return sentences\n",
    "\n",
    "\n",
    "review_to_sentences(train[\"review\"][0], lemmatize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T23:04:59.852621Z",
     "start_time": "2018-12-19T23:00:43.212592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bani5\\AppData\\Roaming\\Python\\Python37\\site-packages\\bs4\\__init__.py:273: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\bani5\\AppData\\Roaming\\Python\\Python37\\site-packages\\bs4\\__init__.py:273: UserWarning: \"b'...'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\bani5\\AppData\\Roaming\\Python\\Python37\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.happierabroad.com\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from unlabeled set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bani5\\AppData\\Roaming\\Python\\Python37\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.archive.org/details/LovefromaStranger\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\bani5\\AppData\\Roaming\\Python\\Python37\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.loosechangeguide.com/LooseChangeGuide.html\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\bani5\\AppData\\Roaming\\Python\\Python37\\site-packages\\bs4\\__init__.py:273: UserWarning: \"b'... ...'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\bani5\\AppData\\Roaming\\Python\\Python37\\site-packages\\bs4\\__init__.py:273: UserWarning: \"b'....'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\bani5\\AppData\\Roaming\\Python\\Python37\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.msnbc.msn.com/id/4972055/site/newsweek/\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\bani5\\AppData\\Roaming\\Python\\Python37\\site-packages\\bs4\\__init__.py:273: UserWarning: \"b'..'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\bani5\\AppData\\Roaming\\Python\\Python37\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.youtube.com/watch?v=a0KSqelmgN8\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\bani5\\AppData\\Roaming\\Python\\Python37\\site-packages\\bs4\\__init__.py:273: UserWarning: \"b'.. .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\bani5\\AppData\\Roaming\\Python\\Python37\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://jake-weird.blogspot.com/2007/08/beneath.html\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "print(\"Parsing sentences from training set\")\n",
    "for review in train[\"review\"]:\n",
    "    sentences += review_to_sentences(review, lemmatize=True)\n",
    "\n",
    "print(\"Parsing sentences from unlabeled set\")\n",
    "for review in unlabeled_train[\"review\"]:\n",
    "    sentences += review_to_sentences(review, lemmatize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T23:05:04.716554Z",
     "start_time": "2018-12-19T23:05:04.713564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "795538\n",
      "['with', 'all', 'this', 'stuff', 'go', 'down', 'at', 'the', 'moment', 'with', 'mj', 'i', 've', 'start', 'listen', 'to', 'his', 'music', ',', 'watch', 'the', 'odd', 'documentary', 'here', 'and', 'there', ',', 'watch', 'the', 'wiz', 'and', 'watch', 'moonwalker', 'again', '.']\n",
      "['my', 'god', ',', 'what', 'a', 'brilliant', 'experience', '.']\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))\n",
    "print(sentences[0])\n",
    "print(sentences[57])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T23:13:01.241708Z",
     "start_time": "2018-12-19T23:11:52.039215Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-20 00:11:52,041 : INFO : collecting all words and their counts\n",
      "2018-12-20 00:11:52,042 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-12-20 00:11:52,082 : INFO : PROGRESS: at sentence #10000, processed 254633 words, keeping 14748 word types\n",
      "2018-12-20 00:11:52,121 : INFO : PROGRESS: at sentence #20000, processed 509007 words, keeping 20656 word types\n",
      "2018-12-20 00:11:52,160 : INFO : PROGRESS: at sentence #30000, processed 756401 words, keeping 24865 word types\n",
      "2018-12-20 00:11:52,198 : INFO : PROGRESS: at sentence #40000, processed 1011564 words, keeping 28468 word types\n",
      "2018-12-20 00:11:52,234 : INFO : PROGRESS: at sentence #50000, processed 1259395 words, keeping 31366 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-20 00:11:52,273 : INFO : PROGRESS: at sentence #60000, processed 1508834 words, keeping 33869 word types\n",
      "2018-12-20 00:11:52,313 : INFO : PROGRESS: at sentence #70000, processed 1760225 words, keeping 36126 word types\n",
      "2018-12-20 00:11:52,351 : INFO : PROGRESS: at sentence #80000, processed 2007022 words, keeping 38188 word types\n",
      "2018-12-20 00:11:52,390 : INFO : PROGRESS: at sentence #90000, processed 2259952 words, keeping 40270 word types\n",
      "2018-12-20 00:11:52,427 : INFO : PROGRESS: at sentence #100000, processed 2510143 words, keeping 42040 word types\n",
      "2018-12-20 00:11:52,465 : INFO : PROGRESS: at sentence #110000, processed 2758616 words, keeping 43669 word types\n",
      "2018-12-20 00:11:52,505 : INFO : PROGRESS: at sentence #120000, processed 3008744 words, keeping 45473 word types\n",
      "2018-12-20 00:11:52,544 : INFO : PROGRESS: at sentence #130000, processed 3263445 words, keeping 46988 word types\n",
      "2018-12-20 00:11:52,582 : INFO : PROGRESS: at sentence #140000, processed 3503763 words, keeping 48319 word types\n",
      "2018-12-20 00:11:52,620 : INFO : PROGRESS: at sentence #150000, processed 3757833 words, keeping 49842 word types\n",
      "2018-12-20 00:11:52,659 : INFO : PROGRESS: at sentence #160000, processed 4009062 words, keeping 51238 word types\n",
      "2018-12-20 00:11:52,705 : INFO : PROGRESS: at sentence #170000, processed 4260979 words, keeping 52529 word types\n",
      "2018-12-20 00:11:52,742 : INFO : PROGRESS: at sentence #180000, processed 4509577 words, keeping 53779 word types\n",
      "2018-12-20 00:11:52,783 : INFO : PROGRESS: at sentence #190000, processed 4763223 words, keeping 54932 word types\n",
      "2018-12-20 00:11:52,823 : INFO : PROGRESS: at sentence #200000, processed 5016234 words, keeping 56092 word types\n",
      "2018-12-20 00:11:52,862 : INFO : PROGRESS: at sentence #210000, processed 5266169 words, keeping 57272 word types\n",
      "2018-12-20 00:11:52,901 : INFO : PROGRESS: at sentence #220000, processed 5519833 words, keeping 58457 word types\n",
      "2018-12-20 00:11:52,940 : INFO : PROGRESS: at sentence #230000, processed 5770664 words, keeping 59601 word types\n",
      "2018-12-20 00:11:52,980 : INFO : PROGRESS: at sentence #240000, processed 6026823 words, keeping 60701 word types\n",
      "2018-12-20 00:11:53,016 : INFO : PROGRESS: at sentence #250000, processed 6268438 words, keeping 61762 word types\n",
      "2018-12-20 00:11:53,054 : INFO : PROGRESS: at sentence #260000, processed 6517014 words, keeping 62775 word types\n",
      "2018-12-20 00:11:53,092 : INFO : PROGRESS: at sentence #270000, processed 6766443 words, keeping 63988 word types\n",
      "2018-12-20 00:11:53,132 : INFO : PROGRESS: at sentence #280000, processed 7020556 words, keeping 65488 word types\n",
      "2018-12-20 00:11:53,169 : INFO : PROGRESS: at sentence #290000, processed 7271681 words, keeping 66849 word types\n",
      "2018-12-20 00:11:53,208 : INFO : PROGRESS: at sentence #300000, processed 7525146 words, keeping 68077 word types\n",
      "2018-12-20 00:11:53,246 : INFO : PROGRESS: at sentence #310000, processed 7779083 words, keeping 69301 word types\n",
      "2018-12-20 00:11:53,286 : INFO : PROGRESS: at sentence #320000, processed 8032197 words, keeping 70566 word types\n",
      "2018-12-20 00:11:53,323 : INFO : PROGRESS: at sentence #330000, processed 8281936 words, keeping 71699 word types\n",
      "2018-12-20 00:11:53,363 : INFO : PROGRESS: at sentence #340000, processed 8540368 words, keeping 72868 word types\n",
      "2018-12-20 00:11:53,406 : INFO : PROGRESS: at sentence #350000, processed 8791811 words, keeping 73942 word types\n",
      "2018-12-20 00:11:53,447 : INFO : PROGRESS: at sentence #360000, processed 9040640 words, keeping 75042 word types\n",
      "2018-12-20 00:11:53,490 : INFO : PROGRESS: at sentence #370000, processed 9296789 words, keeping 76063 word types\n",
      "2018-12-20 00:11:53,531 : INFO : PROGRESS: at sentence #380000, processed 9550910 words, keeping 77153 word types\n",
      "2018-12-20 00:11:53,574 : INFO : PROGRESS: at sentence #390000, processed 9809822 words, keeping 78104 word types\n",
      "2018-12-20 00:11:53,614 : INFO : PROGRESS: at sentence #400000, processed 10060941 words, keeping 79053 word types\n",
      "2018-12-20 00:11:53,652 : INFO : PROGRESS: at sentence #410000, processed 10310360 words, keeping 79945 word types\n",
      "2018-12-20 00:11:53,690 : INFO : PROGRESS: at sentence #420000, processed 10559747 words, keeping 80914 word types\n",
      "2018-12-20 00:11:53,730 : INFO : PROGRESS: at sentence #430000, processed 10816377 words, keeping 81878 word types\n",
      "2018-12-20 00:11:53,773 : INFO : PROGRESS: at sentence #440000, processed 11072300 words, keeping 82807 word types\n",
      "2018-12-20 00:11:53,810 : INFO : PROGRESS: at sentence #450000, processed 11324608 words, keeping 83869 word types\n",
      "2018-12-20 00:11:53,852 : INFO : PROGRESS: at sentence #460000, processed 11587167 words, keeping 84849 word types\n",
      "2018-12-20 00:11:53,889 : INFO : PROGRESS: at sentence #470000, processed 11843839 words, keeping 85645 word types\n",
      "2018-12-20 00:11:53,927 : INFO : PROGRESS: at sentence #480000, processed 12092363 words, keeping 86534 word types\n",
      "2018-12-20 00:11:53,970 : INFO : PROGRESS: at sentence #490000, processed 12348667 words, keeping 87524 word types\n",
      "2018-12-20 00:11:54,009 : INFO : PROGRESS: at sentence #500000, processed 12598939 words, keeping 88373 word types\n",
      "2018-12-20 00:11:54,047 : INFO : PROGRESS: at sentence #510000, processed 12852769 words, keeping 89258 word types\n",
      "2018-12-20 00:11:54,087 : INFO : PROGRESS: at sentence #520000, processed 13104616 words, keeping 90112 word types\n",
      "2018-12-20 00:11:54,126 : INFO : PROGRESS: at sentence #530000, processed 13357741 words, keeping 90880 word types\n",
      "2018-12-20 00:11:54,165 : INFO : PROGRESS: at sentence #540000, processed 13611581 words, keeping 91715 word types\n",
      "2018-12-20 00:11:54,204 : INFO : PROGRESS: at sentence #550000, processed 13866203 words, keeping 92541 word types\n",
      "2018-12-20 00:11:54,243 : INFO : PROGRESS: at sentence #560000, processed 14115821 words, keeping 93369 word types\n",
      "2018-12-20 00:11:54,283 : INFO : PROGRESS: at sentence #570000, processed 14374304 words, keeping 94105 word types\n",
      "2018-12-20 00:11:54,322 : INFO : PROGRESS: at sentence #580000, processed 14624139 words, keeping 94926 word types\n",
      "2018-12-20 00:11:54,363 : INFO : PROGRESS: at sentence #590000, processed 14878053 words, keeping 95722 word types\n",
      "2018-12-20 00:11:54,402 : INFO : PROGRESS: at sentence #600000, processed 15128656 words, keeping 96407 word types\n",
      "2018-12-20 00:11:54,442 : INFO : PROGRESS: at sentence #610000, processed 15378470 words, keeping 97243 word types\n",
      "2018-12-20 00:11:54,480 : INFO : PROGRESS: at sentence #620000, processed 15633640 words, keeping 97959 word types\n",
      "2018-12-20 00:11:54,519 : INFO : PROGRESS: at sentence #630000, processed 15886322 words, keeping 98685 word types\n",
      "2018-12-20 00:11:54,557 : INFO : PROGRESS: at sentence #640000, processed 16134654 words, keeping 99457 word types\n",
      "2018-12-20 00:11:54,599 : INFO : PROGRESS: at sentence #650000, processed 16389219 words, keeping 100208 word types\n",
      "2018-12-20 00:11:54,638 : INFO : PROGRESS: at sentence #660000, processed 16640659 words, keeping 100926 word types\n",
      "2018-12-20 00:11:54,676 : INFO : PROGRESS: at sentence #670000, processed 16892070 words, keeping 101590 word types\n",
      "2018-12-20 00:11:54,715 : INFO : PROGRESS: at sentence #680000, processed 17146171 words, keeping 102266 word types\n",
      "2018-12-20 00:11:54,755 : INFO : PROGRESS: at sentence #690000, processed 17396731 words, keeping 103003 word types\n",
      "2018-12-20 00:11:54,792 : INFO : PROGRESS: at sentence #700000, processed 17653939 words, keeping 103789 word types\n",
      "2018-12-20 00:11:54,833 : INFO : PROGRESS: at sentence #710000, processed 17905781 words, keeping 104412 word types\n",
      "2018-12-20 00:11:54,871 : INFO : PROGRESS: at sentence #720000, processed 18159771 words, keeping 105014 word types\n",
      "2018-12-20 00:11:54,910 : INFO : PROGRESS: at sentence #730000, processed 18414556 words, keeping 105703 word types\n",
      "2018-12-20 00:11:54,949 : INFO : PROGRESS: at sentence #740000, processed 18663672 words, keeping 106390 word types\n",
      "2018-12-20 00:11:54,987 : INFO : PROGRESS: at sentence #750000, processed 18909684 words, keeping 106994 word types\n",
      "2018-12-20 00:11:55,025 : INFO : PROGRESS: at sentence #760000, processed 19157303 words, keeping 107598 word types\n",
      "2018-12-20 00:11:55,064 : INFO : PROGRESS: at sentence #770000, processed 19413372 words, keeping 108336 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-20 00:11:55,104 : INFO : PROGRESS: at sentence #780000, processed 19672156 words, keeping 109008 word types\n",
      "2018-12-20 00:11:55,146 : INFO : PROGRESS: at sentence #790000, processed 19927791 words, keeping 109653 word types\n",
      "2018-12-20 00:11:55,167 : INFO : collected 110074 word types from a corpus of 20066678 raw words and 795538 sentences\n",
      "2018-12-20 00:11:55,168 : INFO : Loading a fresh vocabulary\n",
      "2018-12-20 00:11:55,217 : INFO : effective_min_count=50 retains 12067 unique words (10% of original 110074, drops 98007)\n",
      "2018-12-20 00:11:55,218 : INFO : effective_min_count=50 leaves 19526244 word corpus (97% of original 20066678, drops 540434)\n",
      "2018-12-20 00:11:55,245 : INFO : deleting the raw counts dictionary of 110074 items\n",
      "2018-12-20 00:11:55,249 : INFO : sample=0.001 downsamples 50 most-common words\n",
      "2018-12-20 00:11:55,250 : INFO : downsampling leaves estimated 13228187 word corpus (67.7% of prior 19526244)\n",
      "2018-12-20 00:11:55,279 : INFO : estimated required memory for 120"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 10000 exceeded with 10044 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_features = 500  # Word vector dimensionality\n",
    "min_word_count = 50  # Minimum word count\n",
    "num_workers = 4  # Number of threads to run in parallel\n",
    "context = 10  # Context window size\n",
    "downsampling = 1e-3  # Downsample setting for frequent words\n",
    "\n",
    "print(\"Training model...\")\n",
    "model = word2vec.Word2Vec(\n",
    "    sentences,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context,\n",
    "    sample=downsampling)\n",
    "word2vec.Word2Vec()\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "model_name = \"word2vec.model\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T23:13:17.571365Z",
     "start_time": "2018-12-19T23:13:17.566365Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bani5\\AppData\\Roaming\\Python\\Python37\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'kitchen'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"man woman child kitchen\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T23:13:53.539122Z",
     "start_time": "2018-12-19T23:13:53.534121Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bani5\\AppData\\Roaming\\Python\\Python37\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'berlin'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"france england germany berlin\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T23:14:13.172105Z",
     "start_time": "2018-12-19T23:14:13.166084Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bani5\\AppData\\Roaming\\Python\\Python37\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'austria'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"paris berlin london austria\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T23:15:15.140019Z",
     "start_time": "2018-12-19T23:15:15.133989Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bani5\\AppData\\Roaming\\Python\\Python37\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('woman', 0.6220428347587585),\n",
       " ('lad', 0.5684807300567627),\n",
       " ('lady', 0.5563461780548096),\n",
       " ('monk', 0.5445902943611145),\n",
       " ('millionaire', 0.5421693325042725),\n",
       " ('businessman', 0.5183982253074646),\n",
       " ('priest', 0.5182092189788818),\n",
       " ('sailor', 0.5145820379257202),\n",
       " ('men', 0.5050533413887024),\n",
       " ('person', 0.5049101114273071)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T23:15:24.967012Z",
     "start_time": "2018-12-19T23:15:24.960020Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bani5\\AppData\\Roaming\\Python\\Python37\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('princess', 0.6480422019958496),\n",
       " ('stepmother', 0.5759179592132568),\n",
       " ('maid', 0.572234570980072),\n",
       " ('nun', 0.5567984580993652),\n",
       " ('belle', 0.5451830625534058),\n",
       " ('goddess', 0.5433132648468018),\n",
       " ('regina', 0.5393650531768799),\n",
       " ('widow', 0.5368809103965759),\n",
       " ('prince', 0.5348613858222961),\n",
       " ('victoria', 0.5343594551086426)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"queen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T23:17:59.832581Z",
     "start_time": "2018-12-19T23:17:59.826583Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bani5\\AppData\\Roaming\\Python\\Python37\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('terrible', 0.7406212687492371),\n",
       " ('dreadful', 0.7247092723846436),\n",
       " ('atrocious', 0.718103289604187),\n",
       " ('horrible', 0.7075750231742859),\n",
       " ('horrendous', 0.6855326890945435),\n",
       " ('abysmal', 0.676424503326416),\n",
       " ('horrid', 0.6581128835678101),\n",
       " ('lousy', 0.6520488262176514),\n",
       " ('amateurish', 0.6165722608566284),\n",
       " ('appal', 0.6091347336769104)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"awful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T23:18:45.270141Z",
     "start_time": "2018-12-19T23:18:45.264138Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lol', 0.5132268667221069),\n",
       " ('wow', 0.48045819997787476),\n",
       " ('duh', 0.46121692657470703),\n",
       " ('friggin', 0.4604405164718628),\n",
       " ('ugh', 0.44410884380340576),\n",
       " ('omg', 0.4373909533023834),\n",
       " ('yay', 0.43644386529922485),\n",
       " ('stink', 0.42847511172294617),\n",
       " ('gosh', 0.4257442057132721),\n",
       " ('whoa', 0.42529821395874023)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T23:35:20.080504Z",
     "start_time": "2018-12-19T23:35:20.073465Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bani5\\AppData\\Roaming\\Python\\Python37\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('dog', 0.6666625738143921),\n",
       " ('mouse', 0.6510213017463684),\n",
       " ('pet', 0.6108667254447937),\n",
       " ('sheep', 0.5850355625152588),\n",
       " ('rabbit', 0.5639858245849609),\n",
       " ('bird', 0.5473445653915405),\n",
       " ('puppy', 0.5416003465652466),\n",
       " ('mice', 0.5400309562683105),\n",
       " ('pig', 0.5356342196464539),\n",
       " ('puppies', 0.5168529748916626)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T23:25:02.821573Z",
     "start_time": "2018-12-19T23:25:02.817540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12067, 500)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainables.syn1neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T23:25:24.946560Z",
     "start_time": "2018-12-19T23:25:24.939538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04051628, -0.02039886,  0.01202334, -0.02606667, -0.02133823,\n",
       "       -0.10017185, -0.01272653, -0.09540585, -0.18299694,  0.16361529,\n",
       "       -0.02757043,  0.03140888,  0.04576864,  0.00403805,  0.01216199,\n",
       "       -0.03088489,  0.00419512, -0.03025832,  0.0387293 , -0.00183426,\n",
       "       -0.07627061,  0.02369102,  0.01339156, -0.00823164, -0.06077476,\n",
       "       -0.01229963,  0.08358763, -0.03346688,  0.03895821, -0.05717836,\n",
       "       -0.02232922,  0.07010701,  0.02244833, -0.0275238 , -0.00862076,\n",
       "        0.03182406,  0.08041867, -0.09431239, -0.09653579,  0.03285069,\n",
       "       -0.06863715,  0.05598413, -0.02643139, -0.04322631,  0.04394339,\n",
       "        0.04422955,  0.03573749,  0.01240978,  0.02298628, -0.07040206,\n",
       "        0.01113935,  0.00320343,  0.00068471,  0.03807371, -0.02902559,\n",
       "       -0.00827401,  0.02835255,  0.01023153, -0.08672807, -0.05440461,\n",
       "       -0.00932875,  0.06281601,  0.05953036,  0.00314489,  0.04248114,\n",
       "        0.01662689,  0.02260633,  0.04781896,  0.03756152,  0.0187367 ,\n",
       "       -0.0211102 , -0.02151372, -0.01273669,  0.04762385, -0.0205877 ,\n",
       "        0.01446457,  0.00508795,  0.08123802, -0.020822  , -0.02724543,\n",
       "        0.03615531,  0.05297631, -0.08794723, -0.02688628, -0.01814881,\n",
       "       -0.02163251, -0.00893483,  0.05005152, -0.03254284, -0.04620008,\n",
       "        0.02186418, -0.05756288, -0.05240105,  0.00118793, -0.02225544,\n",
       "       -0.05481861,  0.03866618,  0.05142886,  0.0049962 ,  0.04947511,\n",
       "       -0.01680256,  0.05144122, -0.03512479, -0.05479174, -0.04886568,\n",
       "        0.02293748, -0.00685709,  0.04964456,  0.02053573, -0.01975106,\n",
       "       -0.05356215, -0.05685465, -0.00630646,  0.03734558, -0.01939516,\n",
       "        0.00299266, -0.04776227, -0.03312492, -0.04526945, -0.01870307,\n",
       "       -0.01779334,  0.03379067,  0.01843565, -0.05350063,  0.00793207,\n",
       "       -0.03014884,  0.00308444, -0.05003006,  0.07946686, -0.03538981,\n",
       "        0.06175929,  0.01663893,  0.02207496,  0.07119025,  0.04064601,\n",
       "        0.03938386,  0.00132687, -0.02257028, -0.01737713, -0.05293148,\n",
       "       -0.03842177, -0.01153257, -0.03734633, -0.06216466,  0.06989503,\n",
       "       -0.02582176,  0.00798227,  0.02752795, -0.02218345,  0.02931383,\n",
       "       -0.01112895,  0.03631606, -0.05847981,  0.06187233, -0.02525953,\n",
       "       -0.03042405, -0.09050865, -0.08936386,  0.02389687, -0.01354936,\n",
       "       -0.01173082, -0.10937266,  0.00790721, -0.0382951 ,  0.11561545,\n",
       "        0.04260166, -0.047733  ,  0.06059084, -0.04493141,  0.00423613,\n",
       "       -0.05258096,  0.04654966,  0.01022926, -0.06619696, -0.11681098,\n",
       "        0.05663313,  0.01765704,  0.06453222,  0.03116935,  0.0542195 ,\n",
       "       -0.06123244,  0.07848848, -0.02816539,  0.0741093 , -0.01740181,\n",
       "       -0.01249146, -0.01294281, -0.01803813, -0.00620599,  0.02979212,\n",
       "        0.01029257,  0.00653491,  0.05185866,  0.01275044, -0.0080392 ,\n",
       "        0.00528051,  0.08559463,  0.03323983,  0.01246782,  0.03162359,\n",
       "        0.02457387,  0.00486125,  0.02491626,  0.06570474, -0.03491591,\n",
       "        0.06760018, -0.01032506,  0.02927623,  0.01752467,  0.03396591,\n",
       "       -0.06584834,  0.07038626,  0.01494563,  0.11080885,  0.03463256,\n",
       "       -0.05032956, -0.00084297,  0.00524966,  0.02669476,  0.0295226 ,\n",
       "        0.00020019, -0.03006319,  0.03282411,  0.06463315, -0.10197757,\n",
       "        0.02152937, -0.03970379, -0.06878187,  0.00224988,  0.04556896,\n",
       "        0.0162998 , -0.04465239,  0.01941657,  0.01123396, -0.03198335,\n",
       "        0.01258167,  0.01501378, -0.02252305,  0.03062527,  0.0174049 ,\n",
       "       -0.01149595,  0.01503296,  0.04624217,  0.02247163, -0.00800458,\n",
       "       -0.07409181,  0.01037505, -0.00281353, -0.07267859,  0.00545336,\n",
       "        0.03266406, -0.01457369, -0.00407436, -0.03137269, -0.01846849,\n",
       "       -0.050983  , -0.02795993, -0.06673098,  0.03122441, -0.02517241,\n",
       "       -0.00978553,  0.01994416,  0.05107815, -0.04592172, -0.01242997,\n",
       "       -0.00409949, -0.10193388,  0.06859291, -0.03227726, -0.00940394,\n",
       "        0.00061237, -0.00907454, -0.04793585, -0.05686693,  0.0368599 ,\n",
       "        0.07767482, -0.05223572,  0.01493661,  0.02782485, -0.03381632,\n",
       "       -0.03845244, -0.07505462,  0.05296789, -0.1065715 , -0.05493909,\n",
       "       -0.01502963,  0.05473274, -0.0415142 , -0.03750826,  0.07624659,\n",
       "       -0.02716907, -0.07439014,  0.03133275, -0.07184315, -0.0426532 ,\n",
       "        0.02928337, -0.07106453, -0.0511911 ,  0.04944177, -0.023658  ,\n",
       "       -0.01972075,  0.06951717,  0.06455612,  0.05011935, -0.00910411,\n",
       "       -0.03107941, -0.04244132,  0.01616762, -0.03006717,  0.01559702,\n",
       "       -0.03344622,  0.02761153,  0.02306433, -0.04090084,  0.05920837,\n",
       "       -0.01298793,  0.03409235,  0.0372461 , -0.11038002,  0.04489711,\n",
       "        0.04112092, -0.06674411,  0.05268551, -0.00804899,  0.00718375,\n",
       "       -0.00781136, -0.04234165, -0.06597642,  0.02149656, -0.01704656,\n",
       "       -0.01290247,  0.11244418,  0.05438237,  0.03737685, -0.02895888,\n",
       "       -0.04520024, -0.02679956,  0.00074819, -0.03083109, -0.03026944,\n",
       "       -0.05541971, -0.00112641, -0.07202248,  0.04639976, -0.02554069,\n",
       "       -0.02595876, -0.00711937, -0.03606512, -0.0887976 , -0.07356717,\n",
       "       -0.03734596, -0.02852456, -0.00172549, -0.02200913, -0.0140914 ,\n",
       "       -0.00413133, -0.00192163, -0.01777156, -0.04503257, -0.02272905,\n",
       "        0.04501421, -0.02296552,  0.03706387, -0.0086633 ,  0.02580654,\n",
       "        0.00131052,  0.00992902,  0.00565184,  0.00121524, -0.01462024,\n",
       "        0.00229587, -0.00831975, -0.02445673,  0.0089656 ,  0.01939346,\n",
       "       -0.00994813,  0.00595846, -0.02746619,  0.04433316,  0.04840352,\n",
       "       -0.03402466, -0.06058295,  0.02574213, -0.01149777, -0.03732266,\n",
       "        0.00812338,  0.02664718, -0.04530147,  0.01896507, -0.01296178,\n",
       "        0.0642492 , -0.04455632,  0.04282141, -0.02759364, -0.0091074 ,\n",
       "       -0.0104113 , -0.03002756,  0.08371942,  0.01533778,  0.08364449,\n",
       "        0.05356036,  0.00465543, -0.00926419,  0.01529928,  0.04408941,\n",
       "        0.08086268, -0.09073997, -0.00766576,  0.00952234,  0.02665322,\n",
       "        0.01303521, -0.00297518, -0.03303313,  0.02581329,  0.10201138,\n",
       "        0.07686984,  0.02047941, -0.11231916,  0.02213572, -0.04679072,\n",
       "       -0.0027552 ,  0.04414872, -0.01164965,  0.05596555, -0.01770412,\n",
       "        0.03688301, -0.02380152, -0.00075235, -0.00549375, -0.02592115,\n",
       "        0.06725356, -0.07519948, -0.00312998,  0.04727138,  0.04357738,\n",
       "       -0.02431731, -0.03030466, -0.04497265, -0.05426857, -0.01456833,\n",
       "       -0.02158888,  0.02050307,  0.03008455, -0.02065162,  0.02276447,\n",
       "       -0.01687751, -0.02467613, -0.02769986,  0.05830085, -0.02196183,\n",
       "        0.06490027, -0.03291406, -0.00666211,  0.01311406,  0.01225875,\n",
       "        0.06333099, -0.02099773,  0.09143052, -0.0355939 ,  0.04516547,\n",
       "        0.03762635, -0.04347142,  0.0192916 , -0.05267715, -0.02949807,\n",
       "        0.056593  ,  0.01867927, -0.08607487,  0.0370675 ,  0.04890836,\n",
       "        0.02214964,  0.08660795, -0.06632148, -0.04539943, -0.0423214 ,\n",
       "       -0.05705641,  0.0127572 ,  0.09869447,  0.02682218,  0.04508745,\n",
       "        0.05012768, -0.01925343, -0.05749196, -0.04678269,  0.0381685 ,\n",
       "       -0.04015325,  0.01813472, -0.03708701,  0.09022107, -0.01270925,\n",
       "       -0.00488385,  0.02906393, -0.00678622, -0.00554179, -0.01217607,\n",
       "       -0.00162745,  0.02953755, -0.00173142,  0.04195131,  0.04542672],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"flower\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T23:40:18.864705Z",
     "start_time": "2018-12-19T23:40:18.858672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'watch time chasers , it obvious that it be make by a bunch of friends . maybe they be sit around one day in film school and say , hey , let s pool our money together and make a really bad movie ! or something like that . what ever they say , they still end up make a really bad movie - - dull story , bad script , lame act , poor cinematography , bottom of the barrel stock music , etc . all corner be cut , except the one that would have prevent this film s release . life s like that .'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_vocab = set(model.wv.index2word)\n",
    "word2vec_vocab_size = len(word2vec_vocab)\n",
    "print(word2vec_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T23:41:07.537434Z",
     "start_time": "2018-12-19T23:41:07.529424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.05879681e-05, -3.56698147e-05,  1.42450499e-05,  5.55367878e-05,\n",
       "        5.09753081e-05,  1.00684832e-04, -1.84193341e-04, -1.16128103e-04,\n",
       "        1.93949862e-04, -1.08226159e-04,  5.17251065e-05, -1.91901404e-06,\n",
       "        2.11922816e-05, -5.91590615e-05,  5.28755590e-05, -4.60627552e-06,\n",
       "       -6.18077029e-05,  2.07775906e-06,  1.25279970e-04,  6.01875536e-06,\n",
       "       -1.54932088e-04,  1.57997220e-05,  1.46106759e-05, -2.09213886e-05,\n",
       "       -4.31003136e-05, -8.99111401e-05, -7.77515088e-05,  1.39626500e-04,\n",
       "       -5.35250438e-05, -1.22633619e-05, -6.97180221e-05,  3.76372118e-05,\n",
       "        2.99072873e-08, -1.56479859e-04,  6.04848792e-05,  1.25872350e-04,\n",
       "        6.36449331e-05, -3.65261212e-06, -3.44713480e-05, -9.35974385e-05,\n",
       "       -2.07267221e-04,  5.52353813e-05,  4.13939342e-05,  4.47626417e-06,\n",
       "        1.38951204e-04,  4.77079157e-05,  4.62642383e-05,  5.05216376e-05,\n",
       "        1.47593993e-04,  8.73936297e-05,  9.80005352e-05, -1.00811121e-04,\n",
       "       -1.25117600e-04,  4.94470733e-05,  9.16657063e-06, -5.75173945e-05,\n",
       "       -1.18519108e-06,  1.40001721e-04,  7.88963225e-05,  2.18625246e-05,\n",
       "       -4.52883141e-05,  3.33084608e-04, -9.43498162e-06, -5.30320613e-05,\n",
       "        3.57877798e-05, -1.21640551e-04, -3.59814703e-06, -1.52780092e-04,\n",
       "       -1.06556618e-04, -6.59300058e-05, -1.44681457e-04,  4.25316102e-05,\n",
       "       -2.77202053e-05, -8.43937523e-05, -1.05035288e-04,  1.95893765e-04,\n",
       "        1.48533945e-04,  1.96341643e-04,  3.24981738e-05,  1.95389821e-05,\n",
       "        1.69656996e-04, -2.81966149e-05,  6.21106592e-05, -1.23005913e-04,\n",
       "        1.19451637e-04, -6.14854143e-05, -5.84092413e-05, -4.77938447e-05,\n",
       "       -3.64095831e-06, -2.59472581e-04,  8.61343506e-06,  5.94191770e-05,\n",
       "       -3.43347165e-05, -6.60347796e-05,  1.59565796e-04, -1.03169987e-04,\n",
       "        1.12687470e-04, -1.43933561e-04, -3.40547740e-05,  6.48237547e-05,\n",
       "        8.02786963e-05, -6.84250845e-05,  2.02980173e-05, -2.52959908e-05,\n",
       "       -5.61876695e-05, -2.19266949e-04,  5.67386815e-05, -1.52312168e-06,\n",
       "       -1.46245744e-04,  3.80525053e-05,  3.36324701e-05,  2.29001249e-04,\n",
       "       -1.91575891e-04, -1.00650694e-04, -1.59251736e-04, -8.07689503e-05,\n",
       "       -1.32657588e-04,  9.98912292e-05, -7.02422112e-05, -9.07811263e-05,\n",
       "        6.02863111e-05, -1.55905273e-05,  3.65599517e-05, -3.36134981e-05,\n",
       "       -5.15975080e-05, -7.34193827e-06, -2.19076283e-05,  6.99651064e-05,\n",
       "       -1.04475061e-04,  2.28589415e-05, -2.58717519e-05, -5.91899225e-05,\n",
       "        7.83336436e-05,  7.88667530e-05, -2.19499525e-05,  1.28551925e-04,\n",
       "        1.25399849e-04, -1.80338262e-04, -7.05224156e-05, -9.32019029e-05,\n",
       "       -9.14399152e-06, -2.34337585e-05, -5.49932302e-05,  1.44731384e-04,\n",
       "       -6.61709637e-05, -3.71860042e-05,  7.00601522e-05,  7.29492531e-05,\n",
       "        1.23586113e-04,  1.20555582e-04, -3.94280396e-05, -1.23210950e-04,\n",
       "        6.99063967e-05, -1.66613081e-05,  5.80626875e-05,  4.56352900e-05,\n",
       "       -1.21843899e-04,  2.06557103e-04, -2.38202574e-05,  2.34283052e-05,\n",
       "        1.43204539e-04,  1.70949555e-04, -1.81526466e-05, -3.24828725e-05,\n",
       "        1.04416824e-06, -3.45365224e-05, -2.84367197e-05, -1.27530046e-04,\n",
       "        5.01448922e-05, -1.74550718e-04,  3.61555780e-04, -3.10117437e-04,\n",
       "        1.34093018e-04,  1.81950323e-04, -6.01539687e-05, -1.41923319e-05,\n",
       "        6.59280749e-06, -1.68018334e-04, -1.26863481e-04,  4.38927964e-05,\n",
       "       -3.55684642e-05, -3.26183763e-05,  7.68057944e-05,  7.34704008e-06,\n",
       "       -1.24406681e-04, -2.46745676e-05, -5.47355339e-05, -4.87490033e-05,\n",
       "        1.03736702e-05, -6.12087752e-05, -1.66556056e-04, -8.51161967e-05,\n",
       "        5.74512014e-05,  1.07056858e-05, -1.46426910e-05,  1.89044222e-05,\n",
       "       -8.23067785e-06, -1.39374199e-04,  1.17851130e-04, -1.39128999e-04,\n",
       "       -1.29549400e-04, -8.39559289e-05, -4.78163856e-05, -9.44263447e-05,\n",
       "       -1.00519856e-06, -3.89954948e-05, -2.38557855e-04, -1.57775401e-04,\n",
       "       -1.60777679e-04, -7.68378050e-06,  1.91268788e-04,  7.43650817e-05,\n",
       "       -1.11844682e-04, -7.15836734e-07,  6.40615690e-05,  2.60786692e-05,\n",
       "        8.42867667e-05, -2.31211507e-05,  3.16634068e-05,  3.39961407e-05,\n",
       "        6.50706788e-05,  4.18414274e-05, -9.32044422e-05, -1.93983709e-04,\n",
       "        1.11109031e-04,  1.83495169e-04,  1.28296932e-04,  9.73865390e-05,\n",
       "       -1.28134750e-04, -8.06134412e-05, -2.23427603e-04,  1.13156158e-04,\n",
       "       -8.87490460e-05,  4.39476309e-04,  1.12568232e-04, -7.80500486e-05,\n",
       "        1.40624135e-04,  1.65234655e-04,  2.77133484e-04,  8.52690300e-06,\n",
       "       -9.30529714e-05, -1.04301042e-04, -2.02143929e-04, -1.08174470e-04,\n",
       "       -5.65694572e-05, -6.46725530e-05, -3.07956288e-05,  1.81993062e-04,\n",
       "       -2.37459477e-04,  2.42979528e-04,  3.92762267e-05, -1.00375881e-04,\n",
       "        1.28043161e-04, -3.65226188e-05,  1.59029223e-04, -1.14624490e-05,\n",
       "       -6.85321938e-05,  5.72585341e-05, -5.32612212e-05, -4.84453994e-05,\n",
       "       -1.73001958e-04, -9.81185876e-05, -3.04855203e-04,  1.57123795e-04,\n",
       "       -2.40438327e-04, -5.25867472e-05,  4.16715829e-06, -1.34593094e-04,\n",
       "       -4.86339122e-05,  4.65972298e-05,  5.45423882e-06, -1.89104743e-04,\n",
       "        1.93843123e-04, -3.03558936e-05, -5.05230892e-05,  7.22324912e-05,\n",
       "        3.98985867e-04,  5.96931095e-05, -1.45000333e-04,  9.56583099e-05,\n",
       "       -7.10842214e-05, -1.14859620e-04,  1.11612804e-04,  3.76331765e-04,\n",
       "       -1.42185836e-05, -6.78971919e-05, -2.54803075e-04, -8.09801058e-05,\n",
       "        8.27960102e-05, -1.69272709e-04,  1.31141160e-05,  2.96792481e-04,\n",
       "       -1.16647738e-04,  2.70993623e-05,  2.49043787e-05, -2.13014675e-04,\n",
       "       -9.54842617e-05,  1.89295752e-04, -8.48465934e-05, -1.49939588e-04,\n",
       "       -9.93705107e-05, -1.05250430e-04, -1.76993068e-04,  2.65996805e-05,\n",
       "       -8.10491911e-05,  3.98777729e-06,  2.32394341e-05,  4.84944976e-05,\n",
       "       -5.41098307e-05, -1.96847381e-04,  2.06973578e-04,  4.07475854e-05,\n",
       "       -1.07992630e-04, -2.60639281e-05, -2.18256846e-05,  1.88165504e-05,\n",
       "       -6.14864530e-06, -2.60419547e-05,  1.10561996e-04, -1.41358963e-04,\n",
       "        5.88684707e-05,  6.80260064e-06, -7.66884114e-05,  1.01456724e-04,\n",
       "       -5.64524489e-05, -2.63968413e-05,  2.32394290e-04,  1.48992025e-04,\n",
       "        1.47854109e-04,  1.07984059e-04, -1.53992572e-04,  6.68222274e-05,\n",
       "       -9.57432931e-05,  2.02572664e-05, -5.27346201e-05, -1.57862596e-04,\n",
       "        1.10070388e-04, -1.24906248e-04, -1.52202774e-04, -6.64777690e-05,\n",
       "        7.64307988e-05,  1.37959869e-04, -7.59611939e-05,  1.76445992e-05,\n",
       "       -1.51827207e-05,  4.02200094e-05, -4.32837514e-05, -7.60015901e-05,\n",
       "       -6.44977335e-05, -8.60375512e-05, -7.00582750e-05, -2.31250488e-05,\n",
       "        7.57711750e-05,  2.06639103e-04,  6.65565531e-05, -5.29106728e-05,\n",
       "       -5.77239334e-05,  7.99118061e-05, -1.73380016e-04, -1.05088047e-05,\n",
       "       -3.61459655e-07,  4.04985985e-05, -6.77019343e-05,  2.03070922e-05,\n",
       "       -5.02544981e-06, -2.13657513e-05,  4.30558175e-05, -7.07460786e-05,\n",
       "       -1.32697125e-04, -3.07496754e-04, -4.68690087e-05, -4.54583060e-05,\n",
       "       -4.98387453e-05,  7.27829183e-06,  7.09077794e-05,  3.60298873e-05,\n",
       "       -1.52356097e-05, -1.30808272e-04,  8.95242993e-05, -1.47852697e-04,\n",
       "        5.66950039e-05, -1.15196548e-04, -5.82998146e-05, -2.67286872e-04,\n",
       "        1.08098880e-04,  1.27563035e-04, -2.42788243e-04, -1.69882260e-04,\n",
       "       -8.05778909e-05, -6.64408799e-05, -2.05327451e-04,  1.27914129e-04,\n",
       "       -1.33238078e-04,  2.07603691e-04,  1.00067282e-05,  3.03135803e-05,\n",
       "        4.08892738e-05, -3.35455661e-05,  6.35675897e-05, -3.87577984e-06,\n",
       "       -1.04056962e-04,  1.22946212e-05, -3.59539808e-05,  8.05326708e-05,\n",
       "        1.61546359e-05, -1.15142640e-04,  1.59700321e-05,  2.94761499e-04,\n",
       "        1.66824204e-04, -2.37886474e-04,  1.76571368e-04, -1.12038681e-04,\n",
       "       -7.71792475e-05,  2.19353315e-05,  1.60742347e-04, -7.46502847e-05,\n",
       "        9.35179123e-05,  1.17664895e-04, -3.18146995e-05,  9.55088326e-05,\n",
       "       -1.03240040e-04, -2.33390092e-04, -1.08514665e-04,  4.35665461e-05,\n",
       "        2.30645965e-05, -1.70678773e-04, -1.53759116e-04,  2.72575617e-05,\n",
       "        2.59837034e-05, -1.11001056e-04, -9.92328642e-05, -1.81468422e-04,\n",
       "       -1.04577754e-04,  2.16225890e-04, -1.63321543e-04, -1.41573153e-04,\n",
       "        6.10132010e-05,  1.88959675e-04,  5.91933785e-05,  9.17441721e-05,\n",
       "        1.57966235e-04,  1.51399727e-04, -4.05064602e-05,  6.00793146e-06,\n",
       "       -9.66068837e-05, -1.56128342e-04, -2.20438509e-04,  6.16047400e-05,\n",
       "        3.47241148e-05, -2.92164732e-05, -2.85772585e-05, -3.90888628e-04,\n",
       "       -7.47658632e-05,  5.71681630e-05,  3.12684970e-05, -2.00049210e-04,\n",
       "        9.00592422e-05, -1.27614898e-04,  8.34205712e-05,  4.10049543e-05,\n",
       "       -1.04966974e-04,  5.47738055e-05,  1.59866304e-05, -4.35217771e-05,\n",
       "       -1.64640041e-05, -1.11589899e-04, -5.32532176e-05,  4.15238828e-05,\n",
       "       -4.91220599e-05,  1.39501004e-04,  1.64663506e-05,  1.80088158e-04,\n",
       "        1.08956621e-04, -1.39176671e-04, -4.40913973e-05, -1.37800380e-04,\n",
       "        2.52791892e-06,  1.76881895e-05, -3.01198361e-05,  1.09751927e-05,\n",
       "        1.25921200e-04,  2.72214420e-05,  4.48754217e-05,  1.31042179e-04,\n",
       "        1.01955586e-04, -1.70345884e-05, -2.92731766e-05,  4.71882377e-05,\n",
       "        1.62162178e-04,  1.69176972e-04, -4.78959810e-05, -6.49610884e-05,\n",
       "        2.28259069e-05,  4.64381301e-05, -1.54678681e-04, -7.98984693e-05,\n",
       "        1.11717367e-04, -2.50719924e-04,  1.14291324e-05, -1.42203891e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_average_word2vec(review):\n",
    "    featureVec = np.zeros((num_features, ), dtype=\"float32\")\n",
    "    for word in review.split(\" \"):\n",
    "        if word in word2vec_vocab:\n",
    "            featureVec = np.add(featureVec, model.wv[word])\n",
    "    featureVec = np.divide(featureVec, word2vec_vocab_size)\n",
    "    return featureVec\n",
    "\n",
    "\n",
    "get_average_word2vec(clean_unlabeled_train_reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T00:48:15.963076Z",
     "start_time": "2018-12-20T00:44:29.620058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 18264.07\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 17848.867\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 17751.45\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 17710.213\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 17690.688\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 17680.547\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 17675.209\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 17671.895\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 17669.697\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 17667.318\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 17665.924\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 17665.156\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 17664.318\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 17663.627\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 17662.94\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 17662.365\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 17662.148\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 17662.082\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 17661.906\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 17661.787\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 20, inertia 17661.787\n",
      "center shift 0.000000e+00 within tolerance 6.681592e-09\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 18241.324\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 17816.133\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 17715.43\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 17672.262\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 17654.914\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 17644.416\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 17637.545\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 17633.023\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 17629.846\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 17628.021\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 17626.559\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 17625.947\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 17625.527\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 17625.244\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 17625.096\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 17624.994\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 17624.936\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 17624.936\n",
      "center shift 0.000000e+00 within tolerance 6.681592e-09\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 18279.182\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 17865.996\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 17766.41\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 17727.926\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 17706.047\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 17691.238\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 17681.547\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 17673.426\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 17668.59\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 17665.514\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 17663.016\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 17661.893\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 17659.53\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 17657.441\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 17655.928\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 17654.945\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 17653.7\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 17653.459\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 17653.295\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 17653.057\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 20, inertia 17652.746\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 21, inertia 17652.387\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 22, inertia 17652.387\n",
      "center shift 0.000000e+00 within tolerance 6.681592e-09\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 18252.71\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 17849.424\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 17746.895\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 17708.705\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 17689.432\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 17677.062\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 17670.459\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 17666.785\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 17663.996\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 17662.213\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 17661.371\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 17660.934\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 17660.65\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 17660.459\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 17660.234\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 17659.895\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 17659.188\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 17658.807\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 17658.117\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 17657.287\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 20, inertia 17656.764\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 21, inertia 17656.484\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 22, inertia 17656.377\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 23, inertia 17656.26\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 24, inertia 17656.184\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 25, inertia 17656.184\n",
      "center shift 0.000000e+00 within tolerance 6.681592e-09\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 18296.059\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 17876.328\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 17783.908\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 17746.953\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 17726.684\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 17714.828\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 17707.908\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 17702.164\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 17698.758\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 17696.758\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 17695.969\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 17694.908\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 17694.172\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 17693.826\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 17693.596\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 17693.426\n",
      "start iteration\n",
      "done sorting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end inner loop\n",
      "Iteration 16, inertia 17693.21\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 17693.002\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 17692.871\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 17692.871\n",
      "center shift 0.000000e+00 within tolerance 6.681592e-09\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "k_means = KMeans(\n",
    "    n_clusters=word2vec_vocab_size // 5,\n",
    "    n_init=5,\n",
    "    max_iter=1000,\n",
    "    verbose=True,\n",
    "    tol=1e-6,\n",
    "    n_jobs=-1)\n",
    "cluster_index = k_means.fit_predict(model.trainables.syn1neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T00:48:46.866608Z",
     "start_time": "2018-12-20T00:48:39.008579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0\n",
      "['riders', 'cowboys', 'platoon', 'commando', 'giants', 'sailors', 'fortress', 'wag', 'napoleon', 'inc', 'viking', 'helicopters', 'trench', 'elephants', 'yankee', 'rumble', 'bastards', 'cavalry', 'lions', 'tigers', 'stealth', 'ww', 'royale', 'airplanes', 'armies', 'brotherhood', 'apache', 'saber', 'yokai', 'wrestlers', 'imperial', 'commandos', 'swordplay', 'iwo', 'jima', 'tens', 'colonies', 'battleship']\n",
      "\n",
      "Cluster 1\n",
      "['fellow', 'assistant', 'staff', 'buddies', 'guests', 'frequent', 'photos', 'habit', 'pimp', 'peer', 'lunch', 'girlfriends', 'suggestion', 'colleagues', 'customers', 'colleague', 'client', 'employees', 'honeymoon', 'followers', 'assistance', 'fuss', 'employer', 'sessions', 'boyfriends', 'superiors', 'classmates', 'beers', 'clients', 'homework']\n",
      "\n",
      "Cluster 2\n",
      "['riff', 'exclusively', 'misplace', 'superfluous', 'daft', 'repetition', 'carefree', 'acquaint', 'arbitrary', 'comically', 'unrecognizable', 'ubiquitous', 'faithfully', 'anachronistic', 'fabricate', 'coarse', 'bizarrely', 'vocabulary', 'contrivances', 'pointlessly', 'memorize', 'detest', 'ludicrously', 'mishmash', 'gimmicky', 'asinine', 'incongruous', 'unintelligible', 'louder']\n",
      "\n",
      "Cluster 3\n",
      "['difficulty']\n",
      "\n",
      "Cluster 4\n",
      "['kelly', 'johnny', 'eric', 'simon', 'dick', 'wallace', 'ned', 'preston', 'lucille', 'farley']\n",
      "\n",
      "Cluster 5\n",
      "['significance', 'relevance']\n",
      "\n",
      "Cluster 6\n",
      "['theory', 'conspiracy', 'subplot', 'possibility', 'morality', 'discussion', 'notion', 'subtext']\n",
      "\n",
      "Cluster 7\n",
      "['doc', 'sidekick', 'heston', 'mac', 'stern', 'beery', 'shawn', 'caesar', 'meredith', 'willy', 'raft', 'earp', 'charlton', 'wyatt', 'sgt', 'leung', 'hoskins', 'broderick', 'tuck', 'mantle', 'roosevelt', 'borgnine', 'amiable', 'gosling', 'kiefer', 'col', 'audie', 'kotto', 'pendleton']\n",
      "\n",
      "Cluster 8\n",
      "['ain']\n",
      "\n",
      "Cluster 9\n",
      "['sam', 'tony', 'todd', 'terry', 'carl', 'joshua']\n"
     ]
    }
   ],
   "source": [
    "word_centroid_map = dict(zip(model.wv.index2word, cluster_index))\n",
    "num_centroids = max(word_centroid_map.values()) + 1\n",
    "\n",
    "for cluster in range(0, 10):\n",
    "    print(\"\\nCluster \" + str(cluster))\n",
    "    words = []\n",
    "    for i in range(0, len(word_centroid_map.values())):\n",
    "        if (list(word_centroid_map.values())[i] == cluster):\n",
    "            words.append(list(word_centroid_map.keys())[i])\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T00:50:39.855482Z",
     "start_time": "2018-12-20T00:50:39.852480Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_bag_of_centroids(review):\n",
    "    bag_of_centroids = np.zeros(num_centroids, dtype=\"float32\")\n",
    "    for word in review.split(\" \"):\n",
    "        if word in word_centroid_map:\n",
    "            index = word_centroid_map[word]\n",
    "            bag_of_centroids[index] += 1\n",
    "    return bag_of_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T00:50:44.747454Z",
     "start_time": "2018-12-20T00:50:44.742454Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_word2vec_dataset(clean_reviews):\n",
    "    counter = 0\n",
    "    reviewFeatureVecs = np.zeros(\n",
    "        (len(clean_reviews), num_features + num_centroids), dtype=\"float32\")\n",
    "    for review in clean_reviews:\n",
    "        if counter % 1000 == 0:\n",
    "            print(\"Review \" + str(counter) + \" of \" + str(len(clean_reviews)))\n",
    "        average_word2vec_part = np.array(get_average_word2vec(review))\n",
    "        cluster_word2vec_part = np.array(get_bag_of_centroids(review))\n",
    "        reviewFeatureVecs[counter][:num_features] = average_word2vec_part\n",
    "        reviewFeatureVecs[counter][num_features:] = cluster_word2vec_part\n",
    "        counter = counter + 1\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T00:51:18.124453Z",
     "start_time": "2018-12-20T00:50:49.643504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 25000\n",
      "Review 1000 of 25000\n",
      "Review 2000 of 25000\n",
      "Review 3000 of 25000\n",
      "Review 4000 of 25000\n",
      "Review 5000 of 25000\n",
      "Review 6000 of 25000\n",
      "Review 7000 of 25000\n",
      "Review 8000 of 25000\n",
      "Review 9000 of 25000\n",
      "Review 10000 of 25000\n",
      "Review 11000 of 25000\n",
      "Review 12000 of 25000\n",
      "Review 13000 of 25000\n",
      "Review 14000 of 25000\n",
      "Review 15000 of 25000\n",
      "Review 16000 of 25000\n",
      "Review 17000 of 25000\n",
      "Review 18000 of 25000\n",
      "Review 19000 of 25000\n",
      "Review 20000 of 25000\n",
      "Review 21000 of 25000\n",
      "Review 22000 of 25000\n",
      "Review 23000 of 25000\n",
      "Review 24000 of 25000\n"
     ]
    }
   ],
   "source": [
    "train_word2vec_dataset = get_word2vec_dataset(clean_train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T00:51:50.461489Z",
     "start_time": "2018-12-20T00:51:22.926451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 25000\n",
      "Review 1000 of 25000\n",
      "Review 2000 of 25000\n",
      "Review 3000 of 25000\n",
      "Review 4000 of 25000\n",
      "Review 5000 of 25000\n",
      "Review 6000 of 25000\n",
      "Review 7000 of 25000\n",
      "Review 8000 of 25000\n",
      "Review 9000 of 25000\n",
      "Review 10000 of 25000\n",
      "Review 11000 of 25000\n",
      "Review 12000 of 25000\n",
      "Review 13000 of 25000\n",
      "Review 14000 of 25000\n",
      "Review 15000 of 25000\n",
      "Review 16000 of 25000\n",
      "Review 17000 of 25000\n",
      "Review 18000 of 25000\n",
      "Review 19000 of 25000\n",
      "Review 20000 of 25000\n",
      "Review 21000 of 25000\n",
      "Review 22000 of 25000\n",
      "Review 23000 of 25000\n",
      "Review 24000 of 25000\n"
     ]
    }
   ],
   "source": [
    "test_word2vec_dataset = get_word2vec_dataset(clean_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T00:56:27.305246Z",
     "start_time": "2018-12-20T00:54:46.941278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 2913)\n",
      "(5000, 2913)\n",
      "Naive Bayes done\n",
      "KNN done\n",
      "Neural Network done\n",
      "Random Forest done\n",
      "dict_values([0.7509364374667158, 0.6518264051042562, 0.8742843902339109, 0.8161612592683626])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(200, 100), learning_rate='adaptive',\n",
       "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_2 = train_and_score_classifiers(train_word2vec_dataset,\n",
    "                                           train_labels)\n",
    "best_model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T00:56:44.536533Z",
     "start_time": "2018-12-20T00:56:43.724500Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_submission(\"Andrej_Janchevski_2.csv\", best_model_2, test,\n",
    "                    test_word2vec_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T01:03:36.358230Z",
     "start_time": "2018-12-20T01:03:34.284228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 7913)\n",
      "(25000, 7913)\n"
     ]
    }
   ],
   "source": [
    "train_combined_dataset = np.hstack((train_bow_dataset, train_word2vec_dataset))\n",
    "test_combined_dataset = np.hstack((test_bow_dataset, test_word2vec_dataset))\n",
    "print(train_combined_dataset.shape)\n",
    "print(test_combined_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T01:07:25.230603Z",
     "start_time": "2018-12-20T01:04:01.486240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 7913)\n",
      "(5000, 7913)\n",
      "Naive Bayes done\n",
      "KNN done\n",
      "Neural Network done\n",
      "Random Forest done\n",
      "dict_values([0.7449120017615009, 0.6624664597927165, 0.8809258633402975, 0.8201483194051861])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(200, 100), learning_rate='adaptive',\n",
       "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_3 = train_and_score_classifiers(train_combined_dataset,\n",
    "                                           train_labels)\n",
    "best_model_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T01:08:28.862659Z",
     "start_time": "2018-12-20T01:08:27.384653Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_submission(\"Andrej_Janchevski_3.csv\", best_model_3, test,\n",
    "                    test_combined_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of Words пристапот уште веднаш на почеток за ова податочно множество ни даде задоволителни резултати. <br/>\n",
    "Word2Vec моделот поради малата големина на множеството даваше полоши резултати но со модификации и додавање на кластерирањето на зборовите се приближија резултатите до тие на Bag of Words. <br/>\n",
    "Комбинирањето на двата модела не даде значително подобрување кај резултатите, но сепак така се добиваат најдобри резултати."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "726px",
    "left": "1535px",
    "right": "20px",
    "top": "119px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
